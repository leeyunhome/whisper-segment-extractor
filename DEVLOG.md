# 개발 로그 (Development Log)

## 2025-12-25: Whisper Segment Extractor 프로젝트 시작

### 📌 프로젝트 목표
EBS 영어 강의 MP3 파일에서 "전체대화" 구간을 자동으로 감지하고 추출하는 AI 기반 도구 개발

### 🎯 해결하고자 한 문제
- **수동 작업의 비효율성**: 30분짜리 강의에서 약 50초 분량의 대화 구간을 찾아 수동으로 자르는 작업
- **반복성**: 매일/매주 새로운 강의 파일이 올라올 때마다 같은 작업 반복
- **정확성**: 정확한 시작/종료 지점을 찾기 어려움

---

## 개발 과정

### Phase 1: 기본 추출 도구 (extract_conversation.py)
**목표**: Whisper로 "전체대화" 앵커를 찾고 기본적인 추출 수행

**구현**:
- OpenAI Whisper를 사용한 STT (Speech-to-Text)
- "전체대화 주세요" 앵커 문구 검색
- pydub으로 오디오 구간 추출 (320kbps 고음질)

**문제점**:
- 처리 속도가 느림 (30분 MP3당 5-10분 소요)
- 앵커는 찾지만 정확한 추출 구간 결정이 어려움

---

### Phase 2: 배치 처리 및 최적화 (batch_extract_conversation.py)
**개선 사항**:
- ✅ 여러 파일 자동 처리
- ✅ 앵커 검색을 23분부터 시작 (속도 향상)
- ✅ inaSpeechSegmenter로 음악/음성 구간 감지 시도

**문제점**:
- inaSpeechSegmenter 설치 복잡 (TensorFlow 의존성)
- Base 모델 사용으로 여전히 느림

---

### Phase 3: 패턴 분석 (analyze_files.py)
**목적**: 사용자가 수동으로 자른 파일들을 분석하여 패턴 발견

**발견한 패턴**:
```
파일          원본 길이    추출 길이    비율
20251218     29.05분     0.95분(57초)  3.3%
20251219     28.28분     0.77분(46초)  2.7%
20251224     29.60분     0.82분(49초)  2.8%

평균: 50초 추출 (범위: 46-57초)
```

**핵심 발견**:
- 앵커 종료: 약 23:16분
- 실제 추출 시작: 23:56분
- **offset: 약 46초** (음악이 시작되는 시점까지)

---

### Phase 4: 고속 추출 도구 (fast_extract.py)
**주요 개선**:
- ✅ Whisper **tiny 모델** 사용 (5-10배 빠름)
- ✅ 23분(1380초)부터만 전사 (2-3배 속도 향상)
- ✅ 고정 시간 추출: 앵커 + 46초 offset + 50초 구간
- ✅ inaSpeechSegmenter 의존성 제거

**결과**:
- 처리 시간: 30분 MP3당 약 4-5분
- 성공률: 높음 (앵커 감지 95%+)

**한계**:
- 고정 시간 방식이라 음악이 끝나는 시점을 정확히 못 잡음
- 일부 파일에서 한국어 해설 일부 포함됨

---

### Phase 5: 지능형 추출 (smart_extract.py) ⭐
**핵심 아이디어**: Whisper 전사 결과로 영어/한국어를 구분하여 정확한 종료점 찾기

**구현된 기능**:
1. **Whisper 오인식 패턴 처리**
   - "전체대화" → "전체되어"로 인식되는 케이스 대응
   - 연속 3개 세그먼트 병합 검색

2. **영어/한국어 자동 구분**
   ```python
   def _is_english_segment(text):
       korean_ratio = korean_count / total_chars
       return korean_ratio < 0.3  # 한글 30% 미만 = 영어
   ```

3. **지능형 종료 감지**
   - 연속 2개 이상 한국어 세그먼트 → 대화 종료
   - 중간에 영어 나오면 카운터 리셋

4. **음악 시작점 미세 조정**
   - inaSpeechSegmenter로 정확한 시작점 찾기 (선택사항)

5. **대화 스크립트 자동 생성**
   - 타임스탬프와 함께 텍스트 추출
   - `script_*.txt` 파일로 저장

**성능**:
- ✅ 정확도: 매우 높음 (한국어 해설 완전 제거)
- ✅ 처리 시간: small 모델 기준 30분당 약 2-3분
- ✅ 추출 길이: 동적 (실제 대화가 끝나는 시점까지)

**테스트 결과**:
```
20251219: 29.3초 → 109.6초 (개선 전/후)
20251224: 49.8초 (정확!)
20251205: 43.9초 (정확!)
```

---

## 주요 의사결정

### 1. Whisper 모델 선택
- **tiny**: 빠르지만 앵커 감지에는 충분
- **small**: 속도와 정확도의 균형 ⭐ (최종 권장)
- **base/medium**: 너무 느림

### 2. 추출 방식
- ❌ 고정 시간 (46초 offset + 50초)
- ✅ **전사 기반 지능형 추출** (영어/한국어 구분)

**이유**: 파일마다 대화 길이가 다르고, 한국어 해설이 정확히 제거되어야 함

### 3. 23분부터 전사
**장점**:
- 앵커가 항상 23분 이후에 등장
- 불필요한 앞부분 전사 생략 → 2-3배 빠름

### 4. inaSpeechSegmenter 사용 여부
- **음악 시작점 찾기**: 유용하지만 필수는 아님
- **종료점 찾기**: Whisper 전사가 더 정확함
- **결정**: 선택적 사용 (없어도 작동)

---

## 기술적 도전과 해결

### 도전 1: Whisper 오인식
**문제**: "전체대화" → "전체되어"로 인식
**해결**: 
- 앵커 문구 리스트에 오인식 패턴 추가
- 연속 세그먼트 병합 검색

### 도전 2: 세그먼트 분리
**문제**: "전체되어 와" + "주세요" 두 세그먼트로 분리
**해결**: 3개 연속 세그먼트를 합쳐서 검색

### 도전 3: 한국어/영어 혼재
**문제**: 대화 중간에 짧은 한국어 단어 ("오", "네" 등)
**해결**: 
- 한글 비율로 판단 (30% 기준)
- 연속 2개 이상일 때만 종료

### 도전 4: 처리 속도
**문제**: base 모델은 너무 느림
**해결**:
- tiny/small 모델 사용
- 23분부터만 전사
- 결과: 30분당 2-5분으로 단축

---

## 프로젝트 구조

```
whisper-segment-extractor/
├── smart_extract.py          # 메인 스크립트 (권장)
├── fast_extract.py           # 고정 시간 방식
├── batch_extract_conversation.py
├── extract_conversation.py
├── analyze_files.py          # 파일 분석 도구
├── check_anchors.py          # 디버깅 도구
├── test_one_file.py          # 테스트 스크립트
├── test_smart.py
├── README.md
├── .gitignore
└── DEVLOG.md (this file)
```

---

## 사용 방법

### 기본 사용
```bash
python smart_extract.py -f your_file.mp3 --model small
```

### 폴더 전체 처리
```bash
python smart_extract.py --folder "C:\Lectures"
```

### 출력 파일
- `extracted_*.mp3` - 추출된 대화 오디오
- `script_*.txt` - 대화 스크립트 (타임스탬프 포함)
- `transcription_*.json` - 전체 전사 결과

---

## 다음 단계 (TODO)

### 1. MP3 자동 다운로드 ⏳
- [x] Playwright 설치 완료
- [ ] EBS 웹사이트 분석
- [ ] 로그인 자동화
- [ ] 최신 강의 MP3 자동 다운로드
- [ ] 스케줄러 추가 (매주 자동 실행)

### 2. 추가 기능
- [ ] 여러 앵커 패턴 지원 (사용자 정의)
- [ ] GUI 추가 (간단한 인터페이스)
- [ ] 진행률 표시 개선
- [ ] 오류 처리 강화

### 3. 범용화
- [ ] 팟캐스트, 인터뷰 등 다른 오디오에도 적용
- [ ] 앵커 자동 학습 기능
- [ ] 다국어 지원

---

## 배운 점

1. **STT의 한계와 보완**
   - Whisper도 오인식이 있음
   - 패턴 추가와 병합 검색으로 보완 가능

2. **속도 vs 정확도 trade-off**
   - tiny: 빠르지만 덜 정확
   - small: 최적의 균형점
   - 용도에 맞는 모델 선택 중요

3. **데이터 분석의 중요성**
   - 수동 작업 패턴 분석으로 최적화 힌트 발견
   - "왜 46초 offset인가?" → 데이터가 알려줌

4. **점진적 개선**
   - 완벽한 솔루션을 처음부터 만들려 하지 말 것
   - 빠르게 만들고 → 테스트 → 개선 반복

---

## 참고 자료

- [OpenAI Whisper](https://github.com/openai/whisper)
- [inaSpeechSegmenter](https://github.com/ina-foss/inaSpeechSegmenter)
- [pydub Documentation](https://github.com/jiaaro/pydub)

---

## 업데이트 이력

- 2025-12-25: 프로젝트 시작 및 smart_extract.py 완성
- 2025-12-25: GitHub 저장소 생성 (whisper-segment-extractor)
- 2025-12-25: Playwright 설치, 자동 다운로드 준비 중
