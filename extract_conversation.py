"""
EBS ì˜ì–´ ê°•ì˜ MP3ì—ì„œ "ì „ì²´ëŒ€í™”" ì•µì»¤ë¥¼ ì°¾ì•„ ì˜ì–´ ëŒ€í™” êµ¬ê°„ì„ ìë™ ì¶”ì¶œí•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸

Requirements:
    pip install openai-whisper pydub inaSpeechSegmenter
    
    # FFmpeg ì„¤ì¹˜ í•„ìš” (pydub ì˜ì¡´ì„±)
    # Windows: https://www.ffmpeg.org/download.html
"""

import whisper
import os
from pydub import AudioSegment
from pydub.silence import detect_nonsilent
import json

# Optional: inaSpeechSegmenterë¥¼ ì‚¬ìš©í•˜ë ¤ë©´ ì•„ë˜ ì£¼ì„ í•´ì œ
# from inaSpeechSegmenter import Segmenter


class ConversationExtractor:
    def __init__(self, audio_path, model_size='base'):
        """
        Args:
            audio_path: MP3 íŒŒì¼ ê²½ë¡œ
            model_size: Whisper ëª¨ë¸ í¬ê¸° ('tiny', 'base', 'small', 'medium', 'large')
        """
        self.audio_path = audio_path
        self.model_size = model_size
        self.model = None
        self.transcription = None
        self.anchor_end_time = None
        
    def load_whisper_model(self):
        """Whisper ëª¨ë¸ ë¡œë”©"""
        print(f"ğŸ”„ Whisper ëª¨ë¸ ë¡œë”© ì¤‘... (ëª¨ë¸: {self.model_size})")
        self.model = whisper.load_model(self.model_size)
        print("âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ")
        
    def transcribe_audio(self):
        """ì˜¤ë””ì˜¤ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ (íƒ€ì„ìŠ¤íƒ¬í”„ í¬í•¨)"""
        if self.model is None:
            self.load_whisper_model()
            
        print(f"ğŸ”„ ì˜¤ë””ì˜¤ ì „ì‚¬(transcription) ì‹œì‘: {self.audio_path}")
        
        # word_timestamps=Trueë¡œ ì„¤ì •í•˜ë©´ ë” ì •í™•í•œ íƒ€ì„ìŠ¤íƒ¬í”„ í™•ë³´ ê°€ëŠ¥
        self.transcription = self.model.transcribe(
            self.audio_path,
            language='ko',  # í•œêµ­ì–´ ê°•ì˜ì´ë¯€ë¡œ
            word_timestamps=True,
            verbose=True
        )
        
        print("âœ… ì „ì‚¬ ì™„ë£Œ")
        return self.transcription
    
    def find_anchor_phrase(self, anchor_phrases=["ì „ì²´ëŒ€í™” ì£¼ì„¸ìš”", "ì „ì²´ëŒ€í™”", "ì „ì²´ ëŒ€í™”"]):
        """ì•µì»¤ ë¬¸êµ¬ë¥¼ ì°¾ì•„ ì¢…ë£Œ ì‹œì  ë°˜í™˜"""
        if self.transcription is None:
            print("âš ï¸  ë¨¼ì € transcribe_audio()ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”")
            return None
            
        print(f"ğŸ” ì•µì»¤ ë¬¸êµ¬ ê²€ìƒ‰ ì¤‘: {anchor_phrases}")
        
        # Segments ë‹¨ìœ„ë¡œ ê²€ìƒ‰
        for segment in self.transcription['segments']:
            text = segment['text'].strip()
            
            # ì•µì»¤ ë¬¸êµ¬ê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
            for anchor in anchor_phrases:
                if anchor in text:
                    self.anchor_end_time = segment['end']
                    print(f"âœ… ì•µì»¤ ë°œê²¬: '{text}'")
                    print(f"ğŸ“ ì¢…ë£Œ ì‹œì : {self.anchor_end_time:.2f}ì´ˆ")
                    return self.anchor_end_time
        
        print("âš ï¸  ì•µì»¤ ë¬¸êµ¬ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤")
        return None
    
    def extract_segment_simple(self, duration_seconds=180, output_path='extracted_conversation.mp3'):
        """
        ì•µì»¤ ì´í›„ ê³ ì • ì‹œê°„ë§Œí¼ ì¶”ì¶œ (ê°„ë‹¨í•œ ë°©ë²•)
        
        Args:
            duration_seconds: ì¶”ì¶œí•  ê¸¸ì´ (ì´ˆ), ê¸°ë³¸ 3ë¶„
            output_path: ì¶œë ¥ íŒŒì¼ ê²½ë¡œ
        """
        if self.anchor_end_time is None:
            print("âš ï¸  ë¨¼ì € find_anchor_phrase()ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”")
            return None
            
        print(f"ğŸ”„ ì˜¤ë””ì˜¤ ë¡œë”© ì¤‘: {self.audio_path}")
        audio = AudioSegment.from_mp3(self.audio_path)
        
        # ì‹œì‘/ì¢…ë£Œ ì‹œì  ê³„ì‚° (ë°€ë¦¬ì´ˆ ë‹¨ìœ„)
        start_ms = int(self.anchor_end_time * 1000)
        end_ms = start_ms + (duration_seconds * 1000)
        
        # ì˜¤ë””ì˜¤ íŒŒì¼ ê¸¸ì´ë¥¼ ë„˜ì§€ ì•Šë„ë¡
        end_ms = min(end_ms, len(audio))
        
        print(f"âœ‚ï¸  êµ¬ê°„ ì¶”ì¶œ: {start_ms/1000:.2f}ì´ˆ ~ {end_ms/1000:.2f}ì´ˆ")
        extracted = audio[start_ms:end_ms]
        
        # ê³ ìŒì§ˆë¡œ ì €ì¥
        print(f"ğŸ’¾ ì €ì¥ ì¤‘: {output_path}")
        extracted.export(
            output_path,
            format='mp3',
            bitrate='320k',  # ê³ ìŒì§ˆ
            parameters=["-q:a", "0"]  # ìµœê³  í’ˆì§ˆ
        )
        
        print(f"âœ… ì¶”ì¶œ ì™„ë£Œ: {output_path} ({len(extracted)/1000:.2f}ì´ˆ)")
        return output_path
    
    def extract_segment_smart(self, output_path='extracted_conversation.mp3'):
        """
        inaSpeechSegmenterë¥¼ ì‚¬ìš©í•œ ì§€ëŠ¥í˜• ì¶”ì¶œ
        ìŒì•… ë° ìŒì„± êµ¬ê°„ì„ ìë™ ê°ì§€
        """
        try:
            from inaSpeechSegmenter import Segmenter
        except ImportError:
            print("âš ï¸  inaSpeechSegmenterê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
            print("   pip install inaSpeechSegmenter ë¡œ ì„¤ì¹˜í•˜ì„¸ìš”")
            print("   ëŒ€ì‹  extract_segment_simple()ì„ ì‚¬ìš©í•˜ì„¸ìš”")
            return None
            
        if self.anchor_end_time is None:
            print("âš ï¸  ë¨¼ì € find_anchor_phrase()ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”")
            return None
            
        print("ğŸ”„ ìŒì„±/ìŒì•… ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹œì‘...")
        seg = Segmenter()
        segments = seg(self.audio_path)
        
        # ì•µì»¤ ì´í›„ êµ¬ê°„ë§Œ í•„í„°ë§
        target_segments = []
        for label, start, end in segments:
            if start >= self.anchor_end_time:
                target_segments.append((label, start, end))
                print(f"  - {label}: {start:.2f}ì´ˆ ~ {end:.2f}ì´ˆ")
        
        # ìŒì•…ì´ë‚˜ ì˜ì–´ ìŒì„± êµ¬ê°„ ì°¾ê¸°
        extract_end = self.anchor_end_time
        for label, start, end in target_segments:
            # 'music' ë˜ëŠ” 'female/male' (ì˜ì–´) ë¼ë²¨ì´ë©´ í¬í•¨
            if label in ['music', 'female', 'male']:
                extract_end = end
            else:
                # í•œêµ­ì–´ í•´ì„¤ì´ ë‚˜ì˜¤ë©´ ì¢…ë£Œ
                break
        
        print(f"âœ‚ï¸  ìµœì¢… êµ¬ê°„: {self.anchor_end_time:.2f}ì´ˆ ~ {extract_end:.2f}ì´ˆ")
        
        # ì˜¤ë””ì˜¤ ì¶”ì¶œ
        audio = AudioSegment.from_mp3(self.audio_path)
        start_ms = int(self.anchor_end_time * 1000)
        end_ms = int(extract_end * 1000)
        
        extracted = audio[start_ms:end_ms]
        
        # ì €ì¥
        print(f"ğŸ’¾ ì €ì¥ ì¤‘: {output_path}")
        extracted.export(
            output_path,
            format='mp3',
            bitrate='320k',
            parameters=["-q:a", "0"]
        )
        
        print(f"âœ… ì¶”ì¶œ ì™„ë£Œ: {output_path} ({len(extracted)/1000:.2f}ì´ˆ)")
        return output_path
    
    def save_transcription(self, output_path='transcription.json'):
        """ì „ì‚¬ ê²°ê³¼ë¥¼ JSONìœ¼ë¡œ ì €ì¥"""
        if self.transcription is None:
            print("âš ï¸  ì „ì‚¬ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤")
            return None
            
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(self.transcription, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ’¾ ì „ì‚¬ ê²°ê³¼ ì €ì¥: {output_path}")
        return output_path


# ============= ì‚¬ìš© ì˜ˆì‹œ =============

def main():
    # 1. MP3 íŒŒì¼ ê²½ë¡œ ì„¤ì •
    audio_file = "20251224_173000_b21928fa_mp3.mp3"  # ì—¬ê¸°ì— ì‹¤ì œ íŒŒì¼ ê²½ë¡œ ì…ë ¥
    
    # íŒŒì¼ ì¡´ì¬ í™•ì¸
    if not os.path.exists(audio_file):
        print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {audio_file}")
        print("   audio_file ë³€ìˆ˜ì— ì˜¬ë°”ë¥¸ ê²½ë¡œë¥¼ ì…ë ¥í•˜ì„¸ìš”")
        return
    
    # 2. Extractor ì´ˆê¸°í™”
    extractor = ConversationExtractor(
        audio_path=audio_file,
        model_size='base'  # 'tiny', 'base', 'small', 'medium', 'large' ì¤‘ ì„ íƒ
    )
    
    # 3. ì˜¤ë””ì˜¤ ì „ì‚¬
    extractor.transcribe_audio()
    
    # 4. ì•µì»¤ ë¬¸êµ¬ ì°¾ê¸°
    anchor_time = extractor.find_anchor_phrase()
    
    if anchor_time is None:
        print("ì•µì»¤ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        return
    
    # 5-A. ê°„ë‹¨í•œ ë°©ë²•: ì•µì»¤ ì´í›„ 3ë¶„ ì¶”ì¶œ
    print("\n" + "="*50)
    print("ë°©ë²• 1: ê³ ì • ì‹œê°„(3ë¶„) ì¶”ì¶œ")
    print("="*50)
    extractor.extract_segment_simple(
        duration_seconds=180,
        output_path='extracted_conversation_simple.mp3'
    )
    
    # 5-B. ì§€ëŠ¥í˜• ë°©ë²•: ìŒì„±/ìŒì•… ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‚¬ìš© (ì„ íƒì‚¬í•­)
    # ì£¼ì„ì„ í•´ì œí•˜ê³  inaSpeechSegmenter ì„¤ì¹˜ í›„ ì‚¬ìš©
    # print("\n" + "="*50)
    # print("ë°©ë²• 2: ì§€ëŠ¥í˜• ì„¸ê·¸ë©˜í…Œì´ì…˜")
    # print("="*50)
    # extractor.extract_segment_smart(
    #     output_path='extracted_conversation_smart.mp3'
    # )
    
    # 6. ì „ì‚¬ ê²°ê³¼ ì €ì¥ (ë””ë²„ê¹…ìš©)
    extractor.save_transcription('transcription.json')
    
    print("\nâœ… ëª¨ë“  ì‘ì—… ì™„ë£Œ!")


if __name__ == "__main__":
    main()
