"""
ìŒì•… ê¸°ë°˜ ì§€ëŠ¥í˜• ì¶”ì¶œ ìŠ¤í¬ë¦½íŠ¸ (ê°œì„  ë²„ì „)

ê¸°ëŠ¥:
- ìŒì•…ê³¼ ìŒì„± ìë™ ì¸ì‹ ë° ì •í™•í•œ ì¶”ì¶œ
- ëŒ€í™” ìŠ¤í¬ë¦½íŠ¸ í…ìŠ¤íŠ¸ ì¶”ì¶œ
- 23ë¶„ë¶€í„° ì „ì‚¬ (ì†ë„ í–¥ìƒ)
- ë‹¨ì¼ íŒŒì¼ ì²˜ë¦¬ ì§€ì›
"""

import whisper
import os
import glob
from pydub import AudioSegment
import json
from pathlib import Path
import argparse

try:
    from inaSpeechSegmenter import Segmenter
    HAS_INA = True
except ImportError:
    HAS_INA = False


class SmartConversationExtractor:
    def __init__(self, model_size='tiny'):
        self.model_size = model_size
        self.model = None
        self.segmenter = None
        
    def load_models(self):
        """Whisper ë° inaSpeechSegmenter ë¡œë”©"""
        if self.model is None:
            print(f"ğŸ”„ Whisper ëª¨ë¸ ë¡œë”© ì¤‘... (ëª¨ë¸: {self.model_size})")
            self.model = whisper.load_model(self.model_size)
            print("âœ… Whisper ëª¨ë¸ ë¡œë”© ì™„ë£Œ\n")
        
        if HAS_INA and self.segmenter is None:
            print("ğŸ”„ inaSpeechSegmenter ëª¨ë¸ ë¡œë”© ì¤‘...")
            self.segmenter = Segmenter()
            print("âœ… inaSpeechSegmenter ëª¨ë¸ ë¡œë”© ì™„ë£Œ\n")
    
    def extract_script_text(self, transcription, start_time, end_time):
        """
        ì§€ì •ëœ ì‹œê°„ ë²”ìœ„ì˜ ëŒ€í™” ìŠ¤í¬ë¦½íŠ¸ ì¶”ì¶œ
        
        Args:
            transcription: Whisper ì „ì‚¬ ê²°ê³¼
            start_time: ì‹œì‘ ì‹œê°„ (ì´ˆ)
            end_time: ì¢…ë£Œ ì‹œê°„ (ì´ˆ)
            
        Returns:
            ëŒ€í™” ìŠ¤í¬ë¦½íŠ¸ í…ìŠ¤íŠ¸
        """
        script_lines = []
        
        for segment in transcription['segments']:
            seg_start = segment['start']
            seg_end = segment['end']
            
            # ì¶”ì¶œ êµ¬ê°„ê³¼ ê²¹ì¹˜ëŠ” ì„¸ê·¸ë¨¼íŠ¸ë§Œ
            if seg_start <= end_time and seg_end >= start_time:
                timestamp = f"[{seg_start/60:.2f}ë¶„ - {seg_end/60:.2f}ë¶„]"
                text = segment['text'].strip()
                script_lines.append(f"{timestamp} {text}")
        
        return "\n".join(script_lines)
    
    def _is_korean(self, text):
        """í…ìŠ¤íŠ¸ì— í•œê¸€ì´ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸"""
        for char in text:
            if 'ê°€' <= char <= 'í£':
                return True
        return False
    
    def _is_english_segment(self, text, debug=False):
        """ì„¸ê·¸ë¨¼íŠ¸ê°€ ì£¼ë¡œ ì˜ì–´ì¸ì§€ íŒë‹¨ (ì˜ì–´ ì „ì‚¬ ê¸°ì¤€)"""
        text = text.strip()
        if not text:
            if debug: print(f"      âŒ ë¹ˆ í…ìŠ¤íŠ¸")
            return False
        
        # í•œê¸€ì´ í•˜ë‚˜ë¼ë„ ìˆìœ¼ë©´ í•œêµ­ì–´ (ì˜ì–´ ì „ì‚¬ì—ì„œë„ í•œê¸€ì´ ë‚¨ì„ ìˆ˜ ìˆìŒ)
        if any('ê°€' <= c <= 'í£' for c in text):
            if debug: print(f"      âŒ í•œê¸€ í¬í•¨")
            return False
        
        # 1. í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ì§§ìœ¼ë©´ hallucinationì¼ ìˆ˜ ìˆìœ¼ë‚˜, "Yes", "No" ë“±ì„ ìœ„í•´ 3ì ì´ìƒì´ë©´ í—ˆìš©
        if len(text) < 3:
            if debug: print(f"      âŒ ë„ˆë¬´ ì§§ìŒ ({len(text)}ì < 3ì)")
            return False
        
        # 2. í•œêµ­ì–´ë¥¼ ì˜ì–´ë¡œ ì˜ëª» ì „ì‚¬í•œ íŒ¨í„´ ê°ì§€
        korean_transliteration_patterns = [
            'ì…ì˜ì‘', 'íƒ€ì„', 'íŒ¨í„´', 'ë§Œë‚˜ë³¼ê¹Œìš”', 'ì—°ê¸°', 'ì—°ìŠµ',
            'ì½ì–´ë³¼ê²Œìš”', 'ì „ì²´ëŒ€í™”', 'ë“£ê² ìŠµë‹ˆë‹¤', 'ì£¼ì„¸ìš”',
            'ê·¸ë ‡ì£ ', 'ì—¬ëŸ¬ë¶„', 'ì´ê±°', 'í™œìš©', 'ê°ˆê²Œìš”',
            'ì¡¸ì—…í–ˆì–´', 'ëºì–´', 'íŒŒìš´ë“œ', 'ê°œì›”', 'kg'
        ]
        
        text_lower = text.lower()
        for pattern in korean_transliteration_patterns:
            if pattern.lower() in text_lower:
                if debug: print(f"      âŒ í•œêµ­ì–´ íŒ¨í„´ '{pattern}' ê°ì§€")
                return False
        
        # 3. ë‹¨ì–´ ìˆ˜ ì²´í¬ ì œê±° (ì§§ì€ ì¶”ì„ìƒˆ í—ˆìš©)
        # if len(words) < 2: 
        #    ...
        
        # í•œê¸€ê³¼ í•œêµ­ì–´ íŒ¨í„´ ì²´í¬ë§Œìœ¼ë¡œë„ ì¶©ë¶„ - ì˜ì–´ ë‹¨ì–´ ê²€ì¦ì€ ë„ˆë¬´ ì œí•œì 
        if debug: print(f"      âœ… í†µê³¼!")
        return True
    
    def find_anchor_and_extract_smart(self, audio_path,
                                      search_start_time=1380,
                                      anchor_phrases=["ì „ì²´ëŒ€í™” ì£¼ì„¸ìš”", "ì „ì²´ëŒ€í™”", "ì „ì²´ ëŒ€í™”", "ì „ì²´ë˜ì–´", "ì „ì²´ ë˜ì–´"]):
        """
        ìŒì•… ê¸°ë°˜ ì§€ëŠ¥í˜• ì¶”ì¶œ + Whisper ì „ì‚¬ë¡œ ì˜ì–´ êµ¬ê°„ë§Œ í•„í„°ë§
        
        Returns:
            (ì„±ê³µ ì—¬ë¶€, ì•µì»¤ ì‹œê°„, ì¶”ì¶œ íŒŒì¼ ê²½ë¡œ)
        """
        print(f"{'='*80}")
        print(f"ğŸµ íŒŒì¼: {os.path.basename(audio_path)}")
        print(f"{'='*80}\n")
        
        # ì˜¤ë””ì˜¤ ë¡œë”©
        audio_full = AudioSegment.from_mp3(audio_path)
        start_ms = search_start_time * 1000
        audio_segment = audio_full[start_ms:]
        
        # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
        temp_path = "temp_segment.mp3"
        audio_segment.export(temp_path, format="mp3")
        
        # 1ë‹¨ê³„: í•œêµ­ì–´ ì „ì‚¬ë¡œ ì•µì»¤ ì°¾ê¸°
        print(f"ğŸ”„ 1ë‹¨ê³„: í•œêµ­ì–´ ì „ì‚¬ë¡œ ì•µì»¤ ì°¾ê¸°...")
        result_ko = self.model.transcribe(
            temp_path,
            language='ko',
            word_timestamps=False,
            verbose=False
        )
        
        # ì‹œê°„ ì˜¤í”„ì…‹ ë³´ì • (23ë¶„ ì¶”ê°€)
        for segment in result_ko['segments']:
            segment['start'] += search_start_time
            segment['end'] += search_start_time
        
        # ì„ì‹œ íŒŒì¼ ì‚­ì œ
        os.remove(temp_path)
        
        # ì „ì‚¬ ê²°ê³¼ ì €ì¥ (í•œêµ­ì–´)
        base_name = Path(audio_path).stem
        transcription_path = f"transcription_{base_name}.json"
        with open(transcription_path, 'w', encoding='utf-8') as f:
            json.dump(result_ko, f, ensure_ascii=False, indent=2)
        print(f"ğŸ’¾ í•œêµ­ì–´ ì „ì‚¬ ê²°ê³¼ ì €ì¥: {transcription_path}\n")
        
        # 2. ì•µì»¤ ê²€ìƒ‰ (í•œêµ­ì–´ ì „ì‚¬ ì‚¬ìš©)
        print(f"ğŸ” ì•µì»¤ ë¬¸êµ¬ ê²€ìƒ‰ ì¤‘...")
        anchor_end_time = None
        segments_ko = result_ko['segments']
        
        # ë‹¨ì¼ ì„¸ê·¸ë¨¼íŠ¸ ê²€ìƒ‰
        for segment in segments_ko:
            text = segment['text'].strip()
            
            for anchor in anchor_phrases:
                if anchor in text:
                    anchor_end_time = segment['end']
                    print(f"âœ… ì•µì»¤ ë°œê²¬!")
                    print(f"   í…ìŠ¤íŠ¸: '{text}'")
                    print(f"   ì‹œê°„: {anchor_end_time:.2f}ì´ˆ ({anchor_end_time/60:.2f}ë¶„)\n")
                    break
            
            if anchor_end_time:
                break
        
        # ë³‘í•© ê²€ìƒ‰
        if anchor_end_time is None:
            print(f"ğŸ” ì—°ì† ì„¸ê·¸ë¨¼íŠ¸ ë³‘í•© ê²€ìƒ‰ ì¤‘...")
            for i, segment in enumerate(segments_ko):
                if i < len(segments_ko) - 2:
                    combined_text = (
                        segment['text'] + 
                        segments_ko[i+1]['text'] + 
                        segments_ko[i+2]['text']
                    ).strip()
                    
                    for anchor in anchor_phrases:
                        if anchor in combined_text:
                            anchor_end_time = segments_ko[i+2]['end']
                            print(f"âœ… ì•µì»¤ ë°œê²¬ (ë³‘í•©)!")
                            print(f"   í…ìŠ¤íŠ¸: '{combined_text}'")
                            print(f"   ì‹œê°„: {anchor_end_time:.2f}ì´ˆ ({anchor_end_time/60:.2f}ë¶„)\n")
                            break
                    
                    if anchor_end_time:
                        break
        
        if anchor_end_time is None:
            print(f"âŒ ì•µì»¤ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤\n")
            return False, None, None
        
        # 2ë‹¨ê³„: ì•µì»¤ ì´í›„ êµ¬ê°„ë§Œ ì˜ì–´ë¡œ ì¬ì „ì‚¬
        print(f"ğŸ”„ 2ë‹¨ê³„: ì•µì»¤ ì´í›„ ì˜ì–´ ì „ì‚¬ë¡œ ëŒ€í™” ì¶”ì¶œ...")
        
        # ì•µì»¤ ì´í›„ 5ì´ˆë¶€í„° ì¶”ì¶œ (ì•ˆì „ ë§ˆì§„)
        english_start = max(search_start_time, anchor_end_time - 5)
        english_start_ms = int(english_start * 1000)
        
        audio_english = audio_full[english_start_ms:]
        temp_english_path = "temp_english.mp3"
        audio_english.export(temp_english_path, format="mp3")
        
        # ì˜ì–´ ì „ì‚¬
        result_en = self.model.transcribe(
            temp_english_path,
            language='en',
            initial_prompt="English conversation between native speakers.",
            word_timestamps=False,
            verbose=False,
            no_speech_threshold=0.4,
            condition_on_previous_text=False
        )
        
        # ì‹œê°„ ì˜¤í”„ì…‹ ë³´ì •
        for segment in result_en['segments']:
            segment['start'] += english_start
            segment['end'] += english_start
        
        os.remove(temp_english_path)
        
        # ì˜ì–´ ì „ì‚¬ ê²°ê³¼ë„ ì €ì¥
        transcription_en_path = f"transcription_en_{base_name}.json"
        with open(transcription_en_path, 'w', encoding='utf-8') as f:
            json.dump(result_en, f, ensure_ascii=False, indent=2)
        print(f"ğŸ’¾ ì˜ì–´ ì „ì‚¬ ê²°ê³¼ ì €ì¥: {transcription_en_path}\n")
        
        segments = result_en['segments']  # ì´ì œ ì˜ì–´ ì„¸ê·¸ë¨¼íŠ¸ ì‚¬ìš©
        
        # 3. ì˜ì–´ ëŒ€í™” êµ¬ê°„ ì°¾ê¸° (ì˜ì–´ ì „ì‚¬ ê¸°ì¤€)
        print("ğŸ“ ì˜ì–´ ëŒ€í™” êµ¬ê°„ íƒì§€ ì¤‘...")
        
        english_start_time = None
        english_end_time = None
        timeout = 60.0  # ì•µì»¤ í›„ 60ì´ˆ ì´ë‚´ì— ëŒ€í™” ì‹œì‘í•´ì•¼ í•¨
        gap_threshold = 15.0  # 15ì´ˆ ì´ìƒ ë¹ˆ êµ¬ê°„ì´ë©´ ì¢…ë£Œ (ì™„í™”: 5 â†’ 15)
        last_end_time = anchor_end_time
        
        # ì²« ëŒ€í™” ì„¸íŠ¸ ê°ì§€ìš©
        consecutive_valid = 0  # ì—°ì†ëœ ìœ íš¨ ì„¸ê·¸ë¨¼íŠ¸ ìˆ˜
        first_conversation_min_count = 3  # ìµœì†Œ 3ê°œ ì—°ì† ëŒ€í™”
        first_conversation_found = False  # ì²« ëŒ€í™” ì„¸íŠ¸ ì™„ë£Œ ì—¬ë¶€
        
        for segment in segments:
            seg_start = segment['start']
            seg_end = segment['end']
            text = segment['text'].strip()
            
            # ì•µì»¤ ì´í›„ ì„¸ê·¸ë¨¼íŠ¸ë§Œ í™•ì¸
            if seg_start >= anchor_end_time:
                # íƒ€ì„ì•„ì›ƒ ì²´í¬
                if english_start_time is None and seg_start > anchor_end_time + timeout:
                    print(f"\n  â±ï¸  íƒ€ì„ì•„ì›ƒ: ì•µì»¤ í›„ {timeout}ì´ˆ ë‚´ì— ëŒ€í™”ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤")
                    break
                
                is_english = self._is_english_segment(text, debug=True)
                
                if is_english:
                    # ì²« ì˜ì–´ ì„¸ê·¸ë¨¼íŠ¸
                    if english_start_time is None:
                        english_start_time = seg_start
                        print(f"  ğŸ¬ ëŒ€í™” ì‹œì‘: {seg_start:.1f}ì´ˆ")
                    
                    # ë ì‹œê°„ ì—…ë°ì´íŠ¸
                    english_end_time = seg_end
                    last_end_time = seg_end
                    consecutive_valid += 1
                    print(f"  âœ… {seg_start:.1f}ì´ˆ - {text[:70]}")
                    
                    # ì²« ëŒ€í™” ì„¸íŠ¸ê°€ ì¶©ë¶„íˆ ìŒ“ì´ë©´ í‘œì‹œ
                    if consecutive_valid >= first_conversation_min_count and not first_conversation_found:
                        first_conversation_found = True
                        print(f"  ğŸ’¬ ì²« ëŒ€í™” ì„¸íŠ¸ ê°ì§€ ({consecutive_valid}ê°œ ì—°ì†)")
                    
                else:
                    # ìœ íš¨í•˜ì§€ ì•Šì€ ì„¸ê·¸ë¨¼íŠ¸ (í•œê¸€ ê°ì§€ ë“±)
                    # ëŒ€í™”ê°€ ì¼ë‹¨ ì‹œì‘ëœ í›„ë¼ë©´, í•œê¸€ì´ ë‚˜ì˜¤ê±°ë‚˜ ê¸´ ê³µë°±ì´ ìˆìœ¼ë©´ ì¦‰ì‹œ ì¢…ë£Œ
                    if english_start_time is not None:
                        # 1. í•œê¸€ì´ í¬í•¨ëœ ì„¸ê·¸ë¨¼íŠ¸ì¸ ê²½ìš°
                        if any('ê°€' <= c <= 'í£' for c in text):
                            print(f"\n  â¹ï¸  í•œê¸€ ê°ì§€ (ì„¤ëª… ì‹œì‘): {text[:50]}")
                            print(f"  ğŸ¯ ëŒ€í™” ì¢…ë£Œ ì§ì „: {last_end_time:.1f}ì´ˆ")
                            break
                        
                        # 2. ê³µë°± ì²´í¬ (ì™„í™”: 15ì´ˆ)
                        gap = seg_start - last_end_time
                        if gap > gap_threshold:
                            print(f"\n  â¹ï¸  {gap:.1f}ì´ˆ ê³µë°± ê°ì§€, ëŒ€í™” ì¢…ë£Œ")
                            break
                    
                    consecutive_valid = 0  # ì—°ì†ì„± ë¦¬ì…‹
                    print(f"  â­ï¸  {seg_start:.1f}ì´ˆ - {text[:50]} (ë¬´ì‹œ)")


        
        if english_end_time is None or english_start_time is None:
            print("âš ï¸  ì˜ì–´ ëŒ€í™” êµ¬ê°„ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ê³ ì • ì‹œê°„ ì¶”ì¶œí•©ë‹ˆë‹¤.")
            return self._extract_fixed(audio_path, anchor_end_time, base_name, result)
        
        # 4. ì •ë°€ ì¢…ë£Œ ì§€ì  ì°¾ê¸° (inaSpeechSegmenter í™œìš©)
        extract_start = english_start_time
        extract_end = english_end_time
        
        if HAS_INA:
            if self.segmenter is None:
                self.load_models()
                
            if self.segmenter is not None:
                print("\nğŸ¼ ìŒì•… ê¸°ë°˜ ì •ë°€ ì¢…ë£Œ ì§€ì  ë¶„ì„ ì¤‘...")
                ina_segments = self.segmenter(audio_path)
                
                # Whisperê°€ ì°¾ì€ ì¢…ë£Œ ì§€ì  ì´ì „ì— ì‹œì‘í•œ ë§ˆì§€ë§‰ ìŒì•… ì„¸ê·¸ë¨¼íŠ¸ ì°¾ê¸°
                # ëŒ€í™” ë°°ê²½ ìŒì•…ì€ ë³´í†µ ëŒ€í™”ê°€ ëë‚  ë•Œ ê°™ì´ ëë‚¨
                last_music_end = None
                for label, start, end in ina_segments:
                    if label == 'music':
                        # Whisperê°€ ê°ì§€í•œ ì¢…ë£Œ ì§€ì  ì§ì „ì´ë‚˜ ì•½ê°„ ì§€ë‚œ ì‹œì ê¹Œì§€ì˜ ìŒì•…ë§Œ ì¸ì •
                        if start < english_end_time + 2.0:
                            last_music_end = end
                
                if last_music_end:
                    # ìŒì•… ì¢…ë£Œ ì§€ì ì´ Whisper ì„¸ê·¸ë¨¼íŠ¸ ì¢…ë£Œ ì§€ì ë³´ë‹¤ ì•ì„œë©´ (í•œê¸€ì´ ì„ì˜€ë‹¤ë©´) ë³´ì •
                    # í˜¹ì€ ì•½ê°„ ë’¤ì— ìˆë”ë¼ë„ 5ì´ˆ ì´ë‚´ë¼ë©´ ìŒì•… ì¢…ë£Œ ì§€ì ì„ ìš°ì„ ì‹œ
                    time_diff = last_music_end - extract_end
                    if -10.0 < time_diff < 5.0:
                        print(f"  ğŸµ ë§ˆì§€ë§‰ ìŒì•… ì¢…ë£Œ ê°ì§€: {last_music_end:.2f}ì´ˆ")
                        print(f"  âœ¨ ì¢…ë£Œ ì§€ì  ë³´ì •: {extract_end:.2f}ì´ˆ -> {last_music_end:.2f}ì´ˆ (ì°¨ì´: {time_diff:.2f}ì´ˆ)")
                        extract_end = last_music_end
                    else:
                        print(f"  â„¹ï¸  ìŒì•… ì¢…ë£Œ({last_music_end:.1f}ì´ˆ)ê°€ Whisper ì¢…ë£Œ({extract_end:.1f}ì´ˆ)ì™€ ë„ˆë¬´ ë©€ì–´ ë¬´ì‹œí•©ë‹ˆë‹¤.")

        # 5. ì¶”ì¶œ ì‹œì‘ì  ì„¤ì •
        print(f"\nâœ… ì²« ì˜ì–´ ì„¸ê·¸ë¨¼íŠ¸: {extract_start:.2f}ì´ˆ ({extract_start/60:.2f}ë¶„)")
        print(f"âœ… ë§ˆì§€ë§‰ ì˜ì–´ ì„¸ê·¸ë¨¼íŠ¸: {extract_end:.2f}ì´ˆ ({extract_end/60:.2f}ë¶„)")

        
        # 5. ì˜¤ë””ì˜¤ ì¶”ì¶œ
        duration = extract_end - extract_start
        print(f"\nâœ‚ï¸  êµ¬ê°„ ì¶”ì¶œ:")
        print(f"   ì‹œì‘: {extract_start:.2f}ì´ˆ ({extract_start/60:.2f}ë¶„)")
        print(f"   ì¢…ë£Œ: {extract_end:.2f}ì´ˆ ({extract_end/60:.2f}ë¶„)")
        print(f"   ê¸¸ì´: {duration:.2f}ì´ˆ\n")
        
        start_ms = int(extract_start * 1000)
        end_ms = int(extract_end * 1000)
        
        extracted = audio_full[start_ms:end_ms]
        
        # MP3 ì €ì¥
        output_path = f"extracted_{base_name}.mp3"
        print(f"ğŸ’¾ ì €ì¥ ì¤‘: {output_path}")
        extracted.export(
            output_path,
            format='mp3',
            bitrate='320k',
            parameters=["-q:a", "0"]
        )
        
        actual_duration = len(extracted) / 1000
        print(f"âœ… ì¶”ì¶œ ì™„ë£Œ: {actual_duration:.1f}ì´ˆ\n")
        
        # 6. ëŒ€í™” ìŠ¤í¬ë¦½íŠ¸ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        script_text = self.extract_script_text(result_en, extract_start, extract_end)
        script_path = f"script_{base_name}.txt"
        
        with open(script_path, 'w', encoding='utf-8') as f:
            f.write(f"{'='*80}\n")
            f.write(f"ëŒ€í™” ìŠ¤í¬ë¦½íŠ¸: {os.path.basename(audio_path)}\n")
            f.write(f"{'='*80}\n")
            f.write(f"êµ¬ê°„: {extract_start:.2f}ì´ˆ ~ {extract_end:.2f}ì´ˆ ({duration:.2f}ì´ˆ)\n")
            f.write(f"{'='*80}\n\n")
            f.write(script_text)
        
        print(f"ğŸ“ ëŒ€í™” ìŠ¤í¬ë¦½íŠ¸ ì €ì¥: {script_path}\n")
        
        return True, anchor_end_time, output_path
        
        # 5. ì˜¤ë””ì˜¤ ì¶”ì¶œ
        duration = extract_end - extract_start
        print(f"\nâœ‚ï¸  êµ¬ê°„ ì¶”ì¶œ:")
        print(f"   ì‹œì‘: {extract_start:.2f}ì´ˆ ({extract_start/60:.2f}ë¶„)")
        print(f"   ì¢…ë£Œ: {extract_end:.2f}ì´ˆ ({extract_end/60:.2f}ë¶„)")
        print(f"   ê¸¸ì´: {duration:.2f}ì´ˆ\n")
        
        start_ms = int(extract_start * 1000)
        end_ms = int(extract_end * 1000)
        
        extracted = audio_full[start_ms:end_ms]
        
        # MP3 ì €ì¥
        output_path = f"extracted_{base_name}.mp3"
        print(f"ğŸ’¾ ì €ì¥ ì¤‘: {output_path}")
        extracted.export(
            output_path,
            format='mp3',
            bitrate='320k',
            parameters=["-q:a", "0"]
        )
        
        actual_duration = len(extracted) / 1000
        print(f"âœ… ì¶”ì¶œ ì™„ë£Œ: {actual_duration:.1f}ì´ˆ\n")
        
        # 6. ëŒ€í™” ìŠ¤í¬ë¦½íŠ¸ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        script_text = self.extract_script_text(result, extract_start, extract_end)
        script_path = f"script_{base_name}.txt"
        
        with open(script_path, 'w', encoding='utf-8') as f:
            f.write(f"{'='*80}\n")
            f.write(f"ëŒ€í™” ìŠ¤í¬ë¦½íŠ¸: {os.path.basename(audio_path)}\n")
            f.write(f"{'='*80}\n")
            f.write(f"êµ¬ê°„: {extract_start:.2f}ì´ˆ ~ {extract_end:.2f}ì´ˆ ({duration:.2f}ì´ˆ)\n")
            f.write(f"{'='*80}\n\n")
            f.write(script_text)
        
        print(f"ğŸ“ ëŒ€í™” ìŠ¤í¬ë¦½íŠ¸ ì €ì¥: {script_path}\n")
        
        return True, anchor_end_time, output_path
    
    def _extract_fixed(self, audio_path, anchor_end_time, base_name, transcription):
        """ê³ ì • ì‹œê°„ ì¶”ì¶œ (fallback)"""
        start_offset = 46
        duration = 50
        
        actual_start = anchor_end_time + start_offset
        actual_end = actual_start + duration
        
        print(f"\nâœ‚ï¸  ê³ ì • êµ¬ê°„ ì¶”ì¶œ:")
        print(f"   ì‹œì‘: {actual_start:.2f}ì´ˆ")
        print(f"   ê¸¸ì´: {duration}ì´ˆ\n")
        
        audio = AudioSegment.from_mp3(audio_path)
        start_ms = int(actual_start * 1000)
        end_ms = min(start_ms + (duration * 1000), len(audio))
        
        extracted = audio[start_ms:end_ms]
        
        output_path = f"extracted_{base_name}.mp3"
        print(f"ğŸ’¾ ì €ì¥ ì¤‘: {output_path}")
        extracted.export(
            output_path,
            format='mp3',
            bitrate='320k',
            parameters=["-q:a", "0"]
        )
        
        print(f"âœ… ì¶”ì¶œ ì™„ë£Œ: {len(extracted)/1000:.1f}ì´ˆ\n")
        
        # ëŒ€í™” ìŠ¤í¬ë¦½íŠ¸ ì¶”ì¶œ
        script_text = self.extract_script_text(transcription, actual_start, actual_end)
        script_path = f"script_{base_name}.txt"
        
        with open(script_path, 'w', encoding='utf-8') as f:
            f.write(f"{'='*80}\n")
            f.write(f"ëŒ€í™” ìŠ¤í¬ë¦½íŠ¸: {os.path.basename(audio_path)}\n")
            f.write(f"{'='*80}\n")
            f.write(f"êµ¬ê°„: {actual_start:.2f}ì´ˆ ~ {actual_end:.2f}ì´ˆ ({duration:.2f}ì´ˆ)\n")
            f.write(f"{'='*80}\n\n")
            f.write(script_text)
        
        print(f"ğŸ“ ëŒ€í™” ìŠ¤í¬ë¦½íŠ¸ ì €ì¥: {script_path}\n")
        
        return True, anchor_end_time, output_path
    
    def process_folder(self, folder_path='.',
                      pattern='*.mp3',
                      exclude_patterns=['extracted_', 'transcription_', 'ì™•ì´ˆë³´ì˜ì–´_']):
        """í´ë” ë‚´ MP3 íŒŒì¼ ë°°ì¹˜ ì²˜ë¦¬"""
        self.load_models()
        
        search_path = os.path.join(folder_path, pattern)
        all_files = glob.glob(search_path)
        
        mp3_files = []
        for f in all_files:
            basename = os.path.basename(f)
            should_exclude = False
            for exclude_pattern in exclude_patterns:
                if basename.startswith(exclude_pattern):
                    should_exclude = True
                    break
            if not should_exclude:
                mp3_files.append(f)
        
        if not mp3_files:
            print(f"âš ï¸  ì²˜ë¦¬í•  MP3 íŒŒì¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤")
            return
        
        print(f"\n{'='*80}")
        print(f"ğŸ“ í´ë”: {os.path.abspath(folder_path)}")
        print(f"ğŸµ ë°œê²¬ëœ íŒŒì¼: {len(mp3_files)}ê°œ")
        print(f"{'='*80}\n")
        
        results = []
        
        for i, file_path in enumerate(mp3_files, 1):
            print(f"[{i}/{len(mp3_files)}] ì²˜ë¦¬ ì¤‘...\n")
            
            success, anchor_time, output_path = self.find_anchor_and_extract_smart(file_path)
            
            results.append({
                'file': os.path.basename(file_path),
                'success': success,
                'anchor_time': anchor_time,
                'output': os.path.basename(output_path) if output_path else None
            })
            
            print()
        
        # ê²°ê³¼ ìš”ì•½
        print(f"\n{'='*80}")
        print(f"ğŸ“Š ì²˜ë¦¬ ê²°ê³¼ ìš”ì•½")
        print(f"{'='*80}\n")
        
        success_count = sum(1 for r in results if r['success'])
        print(f"âœ… ì„±ê³µ: {success_count}/{len(results)}ê°œ\n")
        
        for r in results:
            status = "âœ…" if r['success'] else "âŒ"
            print(f"{status} {r['file']}")
            if r['success']:
                print(f"   â†’ {r['output']} (ì•µì»¤: {r['anchor_time']:.1f}ì´ˆ)")
        
        print(f"\n{'='*80}")
        print(f"ğŸ‰ ë°°ì¹˜ ì²˜ë¦¬ ì™„ë£Œ!")
        print(f"{'='*80}\n")


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(description='EBS ì˜ì–´ ê°•ì˜ ëŒ€í™” êµ¬ê°„ ìë™ ì¶”ì¶œ')
    parser.add_argument('--file', '-f', type=str, help='ì²˜ë¦¬í•  íŠ¹ì • MP3 íŒŒì¼ ê²½ë¡œ')
    parser.add_argument('--folder', type=str, default='.', help='ì²˜ë¦¬í•  í´ë” (ê¸°ë³¸: í˜„ì¬ í´ë”)')
    parser.add_argument('--model', type=str, default='tiny', choices=['tiny', 'base', 'small', 'medium', 'large'],
                       help='Whisper ëª¨ë¸ í¬ê¸° (ê¸°ë³¸: tiny)')
    
    args = parser.parse_args()
    
    if not HAS_INA:
        print("="*80)
        print("âš ï¸  inaSpeechSegmenterê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
        print("="*80)
        print("\në‹¤ìŒ ëª…ë ¹ìœ¼ë¡œ ì„¤ì¹˜í•˜ì„¸ìš”:")
        print("  pip install inaSpeechSegmenter tensorflow\n")
        print("ì„¤ì¹˜ ì—†ì´ ê³„ì†í•˜ë ¤ë©´ fast_extract.pyë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.")
        print("="*80)
        return
    
    extractor = SmartConversationExtractor(model_size=args.model)
    
    # ë‹¨ì¼ íŒŒì¼ ì²˜ë¦¬
    if args.file:
        if not os.path.exists(args.file):
            print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {args.file}")
            return
        
        extractor.load_models()
        success, anchor_time, output_path = extractor.find_anchor_and_extract_smart(args.file)
        
        if success:
            print(f"\nâœ… ì²˜ë¦¬ ì™„ë£Œ!")
            print(f"   ì¶œë ¥ íŒŒì¼: {output_path}")
        else:
            print("\nâŒ ì²˜ë¦¬ ì‹¤íŒ¨")
    
    # í´ë” ì „ì²´ ì²˜ë¦¬
    else:
        extractor.process_folder(
            folder_path=args.folder,
            pattern='*.mp3',
            exclude_patterns=['extracted_', 'transcription_', 'ì™•ì´ˆë³´ì˜ì–´_', 'script_']
        )


if __name__ == "__main__":
    main()
