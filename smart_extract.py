"""
ìŒì•… ê¸°ë°˜ ì§€ëŠ¥í˜• ì¶”ì¶œ ìŠ¤í¬ë¦½íŠ¸ (ê°œì„  ë²„ì „)

ê¸°ëŠ¥:
- ìŒì•…ê³¼ ìŒì„± ìë™ ì¸ì‹ ë° ì •í™•í•œ ì¶”ì¶œ
- ëŒ€í™” ìŠ¤í¬ë¦½íŠ¸ í…ìŠ¤íŠ¸ ì¶”ì¶œ
- 23ë¶„ë¶€í„° ì „ì‚¬ (ì†ë„ í–¥ìƒ)
- ë‹¨ì¼ íŒŒì¼ ì²˜ë¦¬ ì§€ì›
"""

import whisper
import os
import glob
from pydub import AudioSegment
import json
from pathlib import Path
import argparse

try:
    from inaSpeechSegmenter import Segmenter
    HAS_INA = True
except ImportError:
    HAS_INA = False


class SmartConversationExtractor:
    def __init__(self, model_size='tiny'):
        self.model_size = model_size
        self.model = None
        self.segmenter = None
        
    def load_models(self):
        """Whisper ë° inaSpeechSegmenter ë¡œë”©"""
        if self.model is None:
            print(f"ğŸ”„ Whisper ëª¨ë¸ ë¡œë”© ì¤‘... (ëª¨ë¸: {self.model_size})")
            self.model = whisper.load_model(self.model_size)
            print("âœ… Whisper ëª¨ë¸ ë¡œë”© ì™„ë£Œ\n")
        
        if HAS_INA and self.segmenter is None:
            print("ğŸ”„ inaSpeechSegmenter ëª¨ë¸ ë¡œë”© ì¤‘...")
            self.segmenter = Segmenter()
            print("âœ… inaSpeechSegmenter ëª¨ë¸ ë¡œë”© ì™„ë£Œ\n")
    
    def extract_script_text(self, transcription, start_time, end_time):
        """
        ì§€ì •ëœ ì‹œê°„ ë²”ìœ„ì˜ ëŒ€í™” ìŠ¤í¬ë¦½íŠ¸ ì¶”ì¶œ
        
        Args:
            transcription: Whisper ì „ì‚¬ ê²°ê³¼
            start_time: ì‹œì‘ ì‹œê°„ (ì´ˆ)
            end_time: ì¢…ë£Œ ì‹œê°„ (ì´ˆ)
            
        Returns:
            ëŒ€í™” ìŠ¤í¬ë¦½íŠ¸ í…ìŠ¤íŠ¸
        """
        script_lines = []
        
        for segment in transcription['segments']:
            seg_start = segment['start']
            seg_end = segment['end']
            
            # ì¶”ì¶œ êµ¬ê°„ê³¼ ê²¹ì¹˜ëŠ” ì„¸ê·¸ë¨¼íŠ¸ë§Œ
            if seg_start <= end_time and seg_end >= start_time:
                timestamp = f"[{seg_start/60:.2f}ë¶„ - {seg_end/60:.2f}ë¶„]"
                text = segment['text'].strip()
                script_lines.append(f"{timestamp} {text}")
        
        return "\n".join(script_lines)
    
    def _is_korean(self, text):
        """í…ìŠ¤íŠ¸ì— í•œê¸€ì´ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸"""
        for char in text:
            if 'ê°€' <= char <= 'í£':
                return True
        return False
    
    def _is_english_segment(self, text, debug=False):
        """ì„¸ê·¸ë¨¼íŠ¸ê°€ ì£¼ë¡œ ì˜ì–´ì¸ì§€ íŒë‹¨ (ì˜ì–´ ì „ì‚¬ ê¸°ì¤€)"""
        text = text.strip()
        if not text:
            if debug: print(f"      âŒ ë¹ˆ í…ìŠ¤íŠ¸")
            return False
        
        # í•œê¸€ì´ í•˜ë‚˜ë¼ë„ ìˆìœ¼ë©´ í•œêµ­ì–´ (ì˜ì–´ ì „ì‚¬ì—ì„œë„ í•œê¸€ì´ ë‚¨ì„ ìˆ˜ ìˆìŒ)
        if any('ê°€' <= c <= 'í£' for c in text):
            if debug: print(f"      âŒ í•œê¸€ í¬í•¨")
            return False
        
        # ì˜ì–´ ì „ì‚¬ ëª¨ë“œì—ì„œ:
        # 1. ê¸¸ì´ê°€ ë„ˆë¬´ ì§§ìœ¼ë©´ ë¬´ì‹œ (hallucinationì´ë‚˜ ë…¸ì´ì¦ˆ)
        if len(text) < 12:  # ì™„í™”: 20 â†’ 12 (ì§§ì€ ì‘ë‹µ í—ˆìš©)
            if debug: print(f"      âŒ ë„ˆë¬´ ì§§ìŒ ({len(text)}ì < 12ì)")
            return False
        
        # 2. í•œêµ­ì–´ë¥¼ ì˜ì–´ë¡œ ì˜ëª» ì „ì‚¬í•œ íŒ¨í„´ ê°ì§€
        korean_transliteration_patterns = [
            'ì…ì˜ì‘', 'íƒ€ì„', 'íŒ¨í„´', 'ë§Œë‚˜ë³¼ê¹Œìš”', 'ì—°ê¸°', 'ì—°ìŠµ',
            'ì½ì–´ë³¼ê²Œìš”', 'ì „ì²´ëŒ€í™”', 'ë“£ê² ìŠµë‹ˆë‹¤', 'ì£¼ì„¸ìš”',
            'ê·¸ë ‡ì£ ', 'ì—¬ëŸ¬ë¶„', 'ì´ê±°', 'í™œìš©', 'ê°ˆê²Œìš”',
            'ì¡¸ì—…í–ˆì–´', 'ëºì–´', 'íŒŒìš´ë“œ', 'ê°œì›”', 'kg'
        ]
        
        text_lower = text.lower()
        for pattern in korean_transliteration_patterns:
            if pattern.lower() in text_lower:
                if debug: print(f"      âŒ í•œêµ­ì–´ íŒ¨í„´ '{pattern}' ê°ì§€")
                return False
        
        # 3. ê³µë°±ìœ¼ë¡œ ë¶„ë¦¬ëœ ë‹¨ì–´ê°€ 2ê°œ ë¯¸ë§Œì´ë©´ ì˜ì‹¬  
        words = text.split()
        if len(words) < 2:  # ì™„í™”: 3 â†’ 2 ("Please." ë“± ì§§ì€ ì‘ë‹µ í—ˆìš©)
            if debug: print(f"      âŒ ë‹¨ì–´ ìˆ˜ ë¶€ì¡± ({len(words)}ê°œ < 2ê°œ)")
            return False
        
        # í•œê¸€ê³¼ í•œêµ­ì–´ íŒ¨í„´ ì²´í¬ë§Œìœ¼ë¡œë„ ì¶©ë¶„ - ì˜ì–´ ë‹¨ì–´ ê²€ì¦ì€ ë„ˆë¬´ ì œí•œì 
        if debug: print(f"      âœ… í†µê³¼!")
        return True
    
    def find_anchor_and_extract_smart(self, audio_path,
                                      search_start_time=1380,
                                      anchor_phrases=["ì „ì²´ëŒ€í™” ì£¼ì„¸ìš”", "ì „ì²´ëŒ€í™”", "ì „ì²´ ëŒ€í™”", "ì „ì²´ë˜ì–´", "ì „ì²´ ë˜ì–´"]):
        """
        ìŒì•… ê¸°ë°˜ ì§€ëŠ¥í˜• ì¶”ì¶œ + Whisper ì „ì‚¬ë¡œ ì˜ì–´ êµ¬ê°„ë§Œ í•„í„°ë§
        
        Returns:
            (ì„±ê³µ ì—¬ë¶€, ì•µì»¤ ì‹œê°„, ì¶”ì¶œ íŒŒì¼ ê²½ë¡œ)
        """
        print(f"{'='*80}")
        print(f"ğŸµ íŒŒì¼: {os.path.basename(audio_path)}")
        print(f"{'='*80}\n")
        
        # ì˜¤ë””ì˜¤ ë¡œë”©
        audio_full = AudioSegment.from_mp3(audio_path)
        start_ms = search_start_time * 1000
        audio_segment = audio_full[start_ms:]
        
        # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
        temp_path = "temp_segment.mp3"
        audio_segment.export(temp_path, format="mp3")
        
        # 1ë‹¨ê³„: í•œêµ­ì–´ ì „ì‚¬ë¡œ ì•µì»¤ ì°¾ê¸°
        print(f"ğŸ”„ 1ë‹¨ê³„: í•œêµ­ì–´ ì „ì‚¬ë¡œ ì•µì»¤ ì°¾ê¸°...")
        result_ko = self.model.transcribe(
            temp_path,
            language='ko',
            word_timestamps=False,
            verbose=False
        )
        
        # ì‹œê°„ ì˜¤í”„ì…‹ ë³´ì • (23ë¶„ ì¶”ê°€)
        for segment in result_ko['segments']:
            segment['start'] += search_start_time
            segment['end'] += search_start_time
        
        # ì„ì‹œ íŒŒì¼ ì‚­ì œ
        os.remove(temp_path)
        
        # ì „ì‚¬ ê²°ê³¼ ì €ì¥ (í•œêµ­ì–´)
        base_name = Path(audio_path).stem
        transcription_path = f"transcription_{base_name}.json"
        with open(transcription_path, 'w', encoding='utf-8') as f:
            json.dump(result_ko, f, ensure_ascii=False, indent=2)
        print(f"ğŸ’¾ í•œêµ­ì–´ ì „ì‚¬ ê²°ê³¼ ì €ì¥: {transcription_path}\n")
        
        # 2. ì•µì»¤ ê²€ìƒ‰ (í•œêµ­ì–´ ì „ì‚¬ ì‚¬ìš©)
        print(f"ğŸ” ì•µì»¤ ë¬¸êµ¬ ê²€ìƒ‰ ì¤‘...")
        anchor_end_time = None
        segments_ko = result_ko['segments']
        
        # ë‹¨ì¼ ì„¸ê·¸ë¨¼íŠ¸ ê²€ìƒ‰
        for segment in segments_ko:
            text = segment['text'].strip()
            
            for anchor in anchor_phrases:
                if anchor in text:
                    anchor_end_time = segment['end']
                    print(f"âœ… ì•µì»¤ ë°œê²¬!")
                    print(f"   í…ìŠ¤íŠ¸: '{text}'")
                    print(f"   ì‹œê°„: {anchor_end_time:.2f}ì´ˆ ({anchor_end_time/60:.2f}ë¶„)\n")
                    break
            
            if anchor_end_time:
                break
        
        # ë³‘í•© ê²€ìƒ‰
        if anchor_end_time is None:
            print(f"ğŸ” ì—°ì† ì„¸ê·¸ë¨¼íŠ¸ ë³‘í•© ê²€ìƒ‰ ì¤‘...")
            for i, segment in enumerate(segments_ko):
                if i < len(segments_ko) - 2:
                    combined_text = (
                        segment['text'] + 
                        segments_ko[i+1]['text'] + 
                        segments_ko[i+2]['text']
                    ).strip()
                    
                    for anchor in anchor_phrases:
                        if anchor in combined_text:
                            anchor_end_time = segments_ko[i+2]['end']
                            print(f"âœ… ì•µì»¤ ë°œê²¬ (ë³‘í•©)!")
                            print(f"   í…ìŠ¤íŠ¸: '{combined_text}'")
                            print(f"   ì‹œê°„: {anchor_end_time:.2f}ì´ˆ ({anchor_end_time/60:.2f}ë¶„)\n")
                            break
                    
                    if anchor_end_time:
                        break
        
        if anchor_end_time is None:
            print(f"âŒ ì•µì»¤ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤\n")
            return False, None, None
        
        # 2ë‹¨ê³„: ì•µì»¤ ì´í›„ êµ¬ê°„ë§Œ ì˜ì–´ë¡œ ì¬ì „ì‚¬
        print(f"ğŸ”„ 2ë‹¨ê³„: ì•µì»¤ ì´í›„ ì˜ì–´ ì „ì‚¬ë¡œ ëŒ€í™” ì¶”ì¶œ...")
        
        # ì•µì»¤ ì´í›„ 5ì´ˆë¶€í„° ì¶”ì¶œ (ì•ˆì „ ë§ˆì§„)
        english_start = max(search_start_time, anchor_end_time - 5)
        english_start_ms = int(english_start * 1000)
        
        audio_english = audio_full[english_start_ms:]
        temp_english_path = "temp_english.mp3"
        audio_english.export(temp_english_path, format="mp3")
        
        # ì˜ì–´ ì „ì‚¬
        result_en = self.model.transcribe(
            temp_english_path,
            language='en',
            initial_prompt="English conversation between native speakers.",
            word_timestamps=False,
            verbose=False,
            no_speech_threshold=0.4,
            condition_on_previous_text=False
        )
        
        # ì‹œê°„ ì˜¤í”„ì…‹ ë³´ì •
        for segment in result_en['segments']:
            segment['start'] += english_start
            segment['end'] += english_start
        
        os.remove(temp_english_path)
        
        # ì˜ì–´ ì „ì‚¬ ê²°ê³¼ë„ ì €ì¥
        transcription_en_path = f"transcription_en_{base_name}.json"
        with open(transcription_en_path, 'w', encoding='utf-8') as f:
            json.dump(result_en, f, ensure_ascii=False, indent=2)
        print(f"ğŸ’¾ ì˜ì–´ ì „ì‚¬ ê²°ê³¼ ì €ì¥: {transcription_en_path}\n")
        
        segments = result_en['segments']  # ì´ì œ ì˜ì–´ ì„¸ê·¸ë¨¼íŠ¸ ì‚¬ìš©
        
        # 3. ì˜ì–´ ëŒ€í™” êµ¬ê°„ ì°¾ê¸° (ì˜ì–´ ì „ì‚¬ ê¸°ì¤€)
        print("ğŸ“ ì˜ì–´ ëŒ€í™” êµ¬ê°„ íƒì§€ ì¤‘...")
        
        english_start_time = None
        english_end_time = None
        timeout = 60.0  # ì•µì»¤ í›„ 60ì´ˆ ì´ë‚´ì— ëŒ€í™” ì‹œì‘í•´ì•¼ í•¨
        gap_threshold = 15.0  # 15ì´ˆ ì´ìƒ ë¹ˆ êµ¬ê°„ì´ë©´ ì¢…ë£Œ (ì™„í™”: 5 â†’ 15)
        last_end_time = anchor_end_time
        
        # ì²« ëŒ€í™” ì„¸íŠ¸ ê°ì§€ìš©
        consecutive_valid = 0  # ì—°ì†ëœ ìœ íš¨ ì„¸ê·¸ë¨¼íŠ¸ ìˆ˜
        first_conversation_min_count = 3  # ìµœì†Œ 3ê°œ ì—°ì† ëŒ€í™”
        first_conversation_found = False  # ì²« ëŒ€í™” ì„¸íŠ¸ ì™„ë£Œ ì—¬ë¶€
        
        for segment in segments:
            seg_start = segment['start']
            seg_end = segment['end']
            text = segment['text'].strip()
            
            # ì•µì»¤ ì´í›„ ì„¸ê·¸ë¨¼íŠ¸ë§Œ í™•ì¸
            if seg_start >= anchor_end_time:
                # íƒ€ì„ì•„ì›ƒ ì²´í¬
                if english_start_time is None and seg_start > anchor_end_time + timeout:
                    print(f"\n  â±ï¸  íƒ€ì„ì•„ì›ƒ: ì•µì»¤ í›„ {timeout}ì´ˆ ë‚´ì— ëŒ€í™”ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤")
                    break
                
                is_english = self._is_english_segment(text, debug=True)
                
                if is_english:
                    # ì²« ì˜ì–´ ì„¸ê·¸ë¨¼íŠ¸
                    if english_start_time is None:
                        english_start_time = seg_start
                        print(f"  ğŸ¬ ëŒ€í™” ì‹œì‘: {seg_start:.1f}ì´ˆ")
                    
                    # ë ì‹œê°„ ì—…ë°ì´íŠ¸
                    english_end_time = seg_end
                    last_end_time = seg_end
                    consecutive_valid += 1
                    print(f"  âœ… {seg_start:.1f}ì´ˆ - {text[:70]}")
                    
                    # ì²« ëŒ€í™” ì„¸íŠ¸ê°€ ì¶©ë¶„íˆ ìŒ“ì´ë©´ í‘œì‹œ
                    if consecutive_valid >= first_conversation_min_count and not first_conversation_found:
                        first_conversation_found = True
                        print(f"  ğŸ’¬ ì²« ëŒ€í™” ì„¸íŠ¸ ê°ì§€ ({consecutive_valid}ê°œ ì—°ì†)")
                    
                else:
                    # ìœ íš¨í•˜ì§€ ì•Šì€ ì„¸ê·¸ë¨¼íŠ¸
                    # ì²« ëŒ€í™” ì„¸íŠ¸ë¥¼ ì°¾ì•˜ê³ , ê¸´ gapê°€ ìˆìœ¼ë©´ ì¢…ë£Œ
                    if first_conversation_found and english_start_time is not None:
                        gap = seg_start - last_end_time
                        if gap > 5.0:  # ì²« ëŒ€í™” í›„ì—ëŠ” 5ì´ˆë§Œ gap í—ˆìš©
                            print(f"\n  ğŸ¯ ì²« ëŒ€í™” ì„¸íŠ¸ ì™„ë£Œ í›„ {gap:.1f}ì´ˆ ê³µë°± ê°ì§€")
                            print(f"  â¹ï¸  ì„ ìƒë‹˜ ì„¤ëª… ì „ì— ì¢…ë£Œí•©ë‹ˆë‹¤")
                            break
                    
                    # ëŒ€í™”ê°€ ì‹œì‘í–ˆì§€ë§Œ ì²« ì„¸íŠ¸ë¥¼ ëª» ì°¾ì•˜ìœ¼ë©´ 15ì´ˆ gap í—ˆìš©
                    if english_start_time is not None and not first_conversation_found:
                        gap = seg_start - last_end_time
                        if gap > gap_threshold:
                            print(f"\n  â¹ï¸  {gap:.1f}ì´ˆ ê³µë°± ê°ì§€, ëŒ€í™” ì¢…ë£Œ")
                            break
                    
                    consecutive_valid = 0  # ì—°ì†ì„± ë¦¬ì…‹
                    print(f"  â­ï¸  {seg_start:.1f}ì´ˆ - {text[:50]} (ë¬´ì‹œ)")


        
        if english_end_time is None or english_start_time is None:
            print("âš ï¸  ì˜ì–´ ëŒ€í™” êµ¬ê°„ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ê³ ì • ì‹œê°„ ì¶”ì¶œí•©ë‹ˆë‹¤.")
            return self._extract_fixed(audio_path, anchor_end_time, base_name, result)
        
        # 4. ì¶”ì¶œ ì‹œì‘ì  ì„¤ì •: ì²« ì˜ì–´ ì„¸ê·¸ë¨¼íŠ¸ë¶€í„°
        extract_start = english_start_time
        extract_end = english_end_time
        print(f"\nâœ… ì²« ì˜ì–´ ì„¸ê·¸ë¨¼íŠ¸: {extract_start:.2f}ì´ˆ ({extract_start/60:.2f}ë¶„)")
        print(f"âœ… ë§ˆì§€ë§‰ ì˜ì–´ ì„¸ê·¸ë¨¼íŠ¸: {extract_end:.2f}ì´ˆ ({extract_end/60:.2f}ë¶„)")

        
        # 5. ì˜¤ë””ì˜¤ ì¶”ì¶œ
        duration = extract_end - extract_start
        print(f"\nâœ‚ï¸  êµ¬ê°„ ì¶”ì¶œ:")
        print(f"   ì‹œì‘: {extract_start:.2f}ì´ˆ ({extract_start/60:.2f}ë¶„)")
        print(f"   ì¢…ë£Œ: {extract_end:.2f}ì´ˆ ({extract_end/60:.2f}ë¶„)")
        print(f"   ê¸¸ì´: {duration:.2f}ì´ˆ\n")
        
        start_ms = int(extract_start * 1000)
        end_ms = int(extract_end * 1000)
        
        extracted = audio_full[start_ms:end_ms]
        
        # MP3 ì €ì¥
        output_path = f"extracted_{base_name}.mp3"
        print(f"ğŸ’¾ ì €ì¥ ì¤‘: {output_path}")
        extracted.export(
            output_path,
            format='mp3',
            bitrate='320k',
            parameters=["-q:a", "0"]
        )
        
        actual_duration = len(extracted) / 1000
        print(f"âœ… ì¶”ì¶œ ì™„ë£Œ: {actual_duration:.1f}ì´ˆ\n")
        
        # 6. ëŒ€í™” ìŠ¤í¬ë¦½íŠ¸ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        script_text = self.extract_script_text(result_en, extract_start, extract_end)
        script_path = f"script_{base_name}.txt"
        
        with open(script_path, 'w', encoding='utf-8') as f:
            f.write(f"{'='*80}\n")
            f.write(f"ëŒ€í™” ìŠ¤í¬ë¦½íŠ¸: {os.path.basename(audio_path)}\n")
            f.write(f"{'='*80}\n")
            f.write(f"êµ¬ê°„: {extract_start:.2f}ì´ˆ ~ {extract_end:.2f}ì´ˆ ({duration:.2f}ì´ˆ)\n")
            f.write(f"{'='*80}\n\n")
            f.write(script_text)
        
        print(f"ğŸ“ ëŒ€í™” ìŠ¤í¬ë¦½íŠ¸ ì €ì¥: {script_path}\n")
        
        return True, anchor_end_time, output_path
        """
        ìŒì•… ê¸°ë°˜ ì§€ëŠ¥í˜• ì¶”ì¶œ
        
        Returns:
            (ì„±ê³µ ì—¬ë¶€, ì•µì»¤ ì‹œê°„, ì¶”ì¶œ íŒŒì¼ ê²½ë¡œ)
        """
        print(f"{'='*80}")
        print(f"ğŸµ íŒŒì¼: {os.path.basename(audio_path)}")
        print(f"{'='*80}\n")
        
        # 1. ì˜¤ë””ì˜¤ë¥¼ 23ë¶„ë¶€í„°ë§Œ ë¡œë“œí•˜ì—¬ ì „ì‚¬ (ì†ë„ í–¥ìƒ)
        print(f"ğŸ”„ ì˜¤ë””ì˜¤ ë¡œë”© ë° ì „ì‚¬ ì¤‘ ({search_start_time/60:.1f}ë¶„ë¶€í„°)...")
        
        # 23ë¶„ë¶€í„° ì˜¤ë””ì˜¤ ì¶”ì¶œ
        audio_full = AudioSegment.from_mp3(audio_path)
        start_ms = search_start_time * 1000
        audio_segment = audio_full[start_ms:]
        
        # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
        temp_path = "temp_segment.mp3"
        audio_segment.export(temp_path, format="mp3")
        
        # ì „ì‚¬ (23ë¶„ ì´í›„ë§Œ)
        result = self.model.transcribe(
            temp_path,
            language='ko',
            word_timestamps=False,
            verbose=False
        )
        
        # ì‹œê°„ ì˜¤í”„ì…‹ ë³´ì • (23ë¶„ ì¶”ê°€)
        for segment in result['segments']:
            segment['start'] += search_start_time
            segment['end'] += search_start_time
        
        # ì„ì‹œ íŒŒì¼ ì‚­ì œ
        os.remove(temp_path)
        
        # ì „ì‚¬ ê²°ê³¼ ì €ì¥
        base_name = Path(audio_path).stem
        transcription_path = f"transcription_{base_name}.json"
        with open(transcription_path, 'w', encoding='utf-8') as f:
            json.dump(result, f, ensure_ascii=False, indent=2)
        print(f"ğŸ’¾ ì „ì‚¬ ê²°ê³¼ ì €ì¥: {transcription_path}\n")
        
        # 2. ì•µì»¤ ê²€ìƒ‰
        print(f"ğŸ” ì•µì»¤ ë¬¸êµ¬ ê²€ìƒ‰ ì¤‘...")
        anchor_end_time = None
        segments = result['segments']
        
        # ë‹¨ì¼ ì„¸ê·¸ë¨¼íŠ¸ ê²€ìƒ‰
        for segment in segments:
            text = segment['text'].strip()
            
            for anchor in anchor_phrases:
                if anchor in text:
                    anchor_end_time = segment['end']
                    print(f"âœ… ì•µì»¤ ë°œê²¬!")
                    print(f"   í…ìŠ¤íŠ¸: '{text}'")
                    print(f"   ì‹œê°„: {anchor_end_time:.2f}ì´ˆ ({anchor_end_time/60:.2f}ë¶„)\n")
                    break
            
            if anchor_end_time:
                break
        
        # ë³‘í•© ê²€ìƒ‰
        if anchor_end_time is None:
            print(f"ğŸ” ì—°ì† ì„¸ê·¸ë¨¼íŠ¸ ë³‘í•© ê²€ìƒ‰ ì¤‘...")
            for i, segment in enumerate(segments):
                if i < len(segments) - 2:
                    combined_text = (
                        segment['text'] + 
                        segments[i+1]['text'] + 
                        segments[i+2]['text']
                    ).strip()
                    
                    for anchor in anchor_phrases:
                        if anchor in combined_text:
                            anchor_end_time = segments[i+2]['end']
                            print(f"âœ… ì•µì»¤ ë°œê²¬ (ë³‘í•©)!")
                            print(f"   í…ìŠ¤íŠ¸: '{combined_text}'")
                            print(f"   ì‹œê°„: {anchor_end_time:.2f}ì´ˆ ({anchor_end_time/60:.2f}ë¶„)\n")
                            break
                    
                    if anchor_end_time:
                        break
        
        if anchor_end_time is None:
            print(f"âŒ ì•µì»¤ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤\n")
            return False, None, None
        
        # 3. inaSpeechSegmenterë¡œ ìŒì•…/ëŒ€í™” êµ¬ê°„ ë¶„ì„
        if not HAS_INA or self.segmenter is None:
            print("âš ï¸  inaSpeechSegmenterë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê³ ì • ì‹œê°„ ì¶”ì¶œí•©ë‹ˆë‹¤.")
            return self._extract_fixed(audio_path, anchor_end_time, base_name, result)
        
        print("ğŸ¼ ìŒì•… ë° ìŒì„± ì„¸ê·¸ë¨¼íŠ¸ ë¶„ì„ ì¤‘...")
        ina_segments = self.segmenter(audio_path)
        
        # ì•µì»¤ ì´í›„ ì„¸ê·¸ë¨¼íŠ¸ë§Œ í•„í„°ë§
        target_segments = [(label, start, end) for label, start, end in ina_segments if start >= anchor_end_time]
        
        if not target_segments:
            print("âš ï¸  ì„¸ê·¸ë¨¼íŠ¸ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ê³ ì • ì‹œê°„ ì¶”ì¶œí•©ë‹ˆë‹¤.")
            return self._extract_fixed(audio_path, anchor_end_time, base_name, result)
        
        print(f"\nğŸ“Š ì•µì»¤ ì´í›„ ì„¸ê·¸ë¨¼íŠ¸ (ì²˜ìŒ 15ê°œ):")
        for i, (label, start, end) in enumerate(target_segments[:15]):
            duration = end - start
            print(f"  {i+1:2d}. {label:12s} {start:7.2f}ì´ˆ ~ {end:7.2f}ì´ˆ (ê¸¸ì´: {duration:5.2f}ì´ˆ)")
        if len(target_segments) > 15:
            print(f"  ... ì™¸ {len(target_segments)-15}ê°œ ì„¸ê·¸ë¨¼íŠ¸")
        
        # 4. ìŒì•…/ëŒ€í™” ì‹œì‘ê³¼ ë ì°¾ê¸°
        extract_start = None
        extract_end = None
        
        # ìŒì•…ì´ë‚˜ ì˜ì–´ ìŒì„±ì´ ì‹œì‘ë˜ëŠ” ì§€ì  ì°¾ê¸°
        for label, start, end in target_segments:
            if label in ['music', 'male', 'female']:
                extract_start = start
                break
        
        if extract_start is None:
            print("\nâš ï¸  ìŒì•…/ëŒ€í™” ì‹œì‘ì ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì•µì»¤ ì§í›„ë¶€í„° ì‹œì‘í•©ë‹ˆë‹¤.")
            extract_start = anchor_end_time
        
        # ìŒì•…/ëŒ€í™”ê°€ ëë‚˜ëŠ” ì§€ì  ì°¾ê¸°
        extract_end = extract_start
        
        # ê°œì„ ëœ ì¢…ë£Œ ê°ì§€ ë¡œì§
        # - ì§§ì€ ì¹¨ë¬µ(3ì´ˆ ì´í•˜)ì€ í—ˆìš© (ì§ˆë¬¸-ëŒ€ë‹µ ì‚¬ì´)
        # - ì•„ì£¼ ê¸´ ì¹¨ë¬µ(5ì´ˆ ì´ìƒ)ì´ë‚˜ í•œêµ­ì–´ ìŒì„±ì´ ë‚˜ì˜¤ë©´ ì¢…ë£Œ
        long_silence_threshold = 5.0  # 5ì´ˆ ì´ìƒ ì¹¨ë¬µ: ëŒ€í™” ì¢…ë£Œ
        
        content_found = False  # music/male/femaleì„ í•œ ë²ˆì´ë¼ë„ ë§Œë‚¬ëŠ”ì§€
        last_content_end = extract_start  # ë§ˆì§€ë§‰ ì½˜í…ì¸ ê°€ ëë‚œ ì‹œì 
        
        for label, start, end in target_segments:
            if start >= extract_start:
                # music, male, female: ê³„ì† í¬í•¨
                if label in ['music', 'male', 'female']:
                    extract_end = end
                    last_content_end = end
                    content_found = True
                    
                elif label == 'noEnergy':
                    duration = end - start
                    # ì•„ì£¼ ê¸´ ì¹¨ë¬µ: ëŒ€í™”ê°€ ì™„ì „íˆ ëë‚¨
                    if duration > long_silence_threshold and content_found:
                        print(f"\n  â¹ï¸  ê¸´ ì¹¨ë¬µ ê°ì§€ ({duration:.2f}ì´ˆ > {long_silence_threshold}ì´ˆ), ëŒ€í™” ì¢…ë£Œ")
                        extract_end = last_content_end
                        break
                    # ì§§ì€ ì¹¨ë¬µì€ ê·¸ëƒ¥ ë„˜ì–´ê° (ì§ˆë¬¸-ëŒ€ë‹µ ì‚¬ì´)
                    
                else:
                    # í•œêµ­ì–´ ë“± ê¸°íƒ€ ìŒì„±: ì¦‰ì‹œ ì¢…ë£Œ
                    if content_found:
                        print(f"\n  â¹ï¸  í•œêµ­ì–´ ìŒì„± ê°ì§€ (ë¼ë²¨: {label}), ëŒ€í™” ì¢…ë£Œ")
                        extract_end = last_content_end
                        break
        
        # 5. ì˜¤ë””ì˜¤ ì¶”ì¶œ
        duration = extract_end - extract_start
        print(f"\nâœ‚ï¸  êµ¬ê°„ ì¶”ì¶œ:")
        print(f"   ì‹œì‘: {extract_start:.2f}ì´ˆ ({extract_start/60:.2f}ë¶„)")
        print(f"   ì¢…ë£Œ: {extract_end:.2f}ì´ˆ ({extract_end/60:.2f}ë¶„)")
        print(f"   ê¸¸ì´: {duration:.2f}ì´ˆ\n")
        
        start_ms = int(extract_start * 1000)
        end_ms = int(extract_end * 1000)
        
        extracted = audio_full[start_ms:end_ms]
        
        # MP3 ì €ì¥
        output_path = f"extracted_{base_name}.mp3"
        print(f"ğŸ’¾ ì €ì¥ ì¤‘: {output_path}")
        extracted.export(
            output_path,
            format='mp3',
            bitrate='320k',
            parameters=["-q:a", "0"]
        )
        
        actual_duration = len(extracted) / 1000
        print(f"âœ… ì¶”ì¶œ ì™„ë£Œ: {actual_duration:.1f}ì´ˆ\n")
        
        # 6. ëŒ€í™” ìŠ¤í¬ë¦½íŠ¸ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        script_text = self.extract_script_text(result, extract_start, extract_end)
        script_path = f"script_{base_name}.txt"
        
        with open(script_path, 'w', encoding='utf-8') as f:
            f.write(f"{'='*80}\n")
            f.write(f"ëŒ€í™” ìŠ¤í¬ë¦½íŠ¸: {os.path.basename(audio_path)}\n")
            f.write(f"{'='*80}\n")
            f.write(f"êµ¬ê°„: {extract_start:.2f}ì´ˆ ~ {extract_end:.2f}ì´ˆ ({duration:.2f}ì´ˆ)\n")
            f.write(f"{'='*80}\n\n")
            f.write(script_text)
        
        print(f"ğŸ“ ëŒ€í™” ìŠ¤í¬ë¦½íŠ¸ ì €ì¥: {script_path}\n")
        
        return True, anchor_end_time, output_path
    
    def _extract_fixed(self, audio_path, anchor_end_time, base_name, transcription):
        """ê³ ì • ì‹œê°„ ì¶”ì¶œ (fallback)"""
        start_offset = 46
        duration = 50
        
        actual_start = anchor_end_time + start_offset
        actual_end = actual_start + duration
        
        print(f"\nâœ‚ï¸  ê³ ì • êµ¬ê°„ ì¶”ì¶œ:")
        print(f"   ì‹œì‘: {actual_start:.2f}ì´ˆ")
        print(f"   ê¸¸ì´: {duration}ì´ˆ\n")
        
        audio = AudioSegment.from_mp3(audio_path)
        start_ms = int(actual_start * 1000)
        end_ms = min(start_ms + (duration * 1000), len(audio))
        
        extracted = audio[start_ms:end_ms]
        
        output_path = f"extracted_{base_name}.mp3"
        print(f"ğŸ’¾ ì €ì¥ ì¤‘: {output_path}")
        extracted.export(
            output_path,
            format='mp3',
            bitrate='320k',
            parameters=["-q:a", "0"]
        )
        
        print(f"âœ… ì¶”ì¶œ ì™„ë£Œ: {len(extracted)/1000:.1f}ì´ˆ\n")
        
        # ëŒ€í™” ìŠ¤í¬ë¦½íŠ¸ ì¶”ì¶œ
        script_text = self.extract_script_text(transcription, actual_start, actual_end)
        script_path = f"script_{base_name}.txt"
        
        with open(script_path, 'w', encoding='utf-8') as f:
            f.write(f"{'='*80}\n")
            f.write(f"ëŒ€í™” ìŠ¤í¬ë¦½íŠ¸: {os.path.basename(audio_path)}\n")
            f.write(f"{'='*80}\n")
            f.write(f"êµ¬ê°„: {actual_start:.2f}ì´ˆ ~ {actual_end:.2f}ì´ˆ ({duration:.2f}ì´ˆ)\n")
            f.write(f"{'='*80}\n\n")
            f.write(script_text)
        
        print(f"ğŸ“ ëŒ€í™” ìŠ¤í¬ë¦½íŠ¸ ì €ì¥: {script_path}\n")
        
        return True, anchor_end_time, output_path
    
    def process_folder(self, folder_path='.',
                      pattern='*.mp3',
                      exclude_patterns=['extracted_', 'transcription_', 'ì™•ì´ˆë³´ì˜ì–´_']):
        """í´ë” ë‚´ MP3 íŒŒì¼ ë°°ì¹˜ ì²˜ë¦¬"""
        self.load_models()
        
        search_path = os.path.join(folder_path, pattern)
        all_files = glob.glob(search_path)
        
        mp3_files = []
        for f in all_files:
            basename = os.path.basename(f)
            should_exclude = False
            for exclude_pattern in exclude_patterns:
                if basename.startswith(exclude_pattern):
                    should_exclude = True
                    break
            if not should_exclude:
                mp3_files.append(f)
        
        if not mp3_files:
            print(f"âš ï¸  ì²˜ë¦¬í•  MP3 íŒŒì¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤")
            return
        
        print(f"\n{'='*80}")
        print(f"ğŸ“ í´ë”: {os.path.abspath(folder_path)}")
        print(f"ğŸµ ë°œê²¬ëœ íŒŒì¼: {len(mp3_files)}ê°œ")
        print(f"{'='*80}\n")
        
        results = []
        
        for i, file_path in enumerate(mp3_files, 1):
            print(f"[{i}/{len(mp3_files)}] ì²˜ë¦¬ ì¤‘...\n")
            
            success, anchor_time, output_path = self.find_anchor_and_extract_smart(file_path)
            
            results.append({
                'file': os.path.basename(file_path),
                'success': success,
                'anchor_time': anchor_time,
                'output': os.path.basename(output_path) if output_path else None
            })
            
            print()
        
        # ê²°ê³¼ ìš”ì•½
        print(f"\n{'='*80}")
        print(f"ğŸ“Š ì²˜ë¦¬ ê²°ê³¼ ìš”ì•½")
        print(f"{'='*80}\n")
        
        success_count = sum(1 for r in results if r['success'])
        print(f"âœ… ì„±ê³µ: {success_count}/{len(results)}ê°œ\n")
        
        for r in results:
            status = "âœ…" if r['success'] else "âŒ"
            print(f"{status} {r['file']}")
            if r['success']:
                print(f"   â†’ {r['output']} (ì•µì»¤: {r['anchor_time']:.1f}ì´ˆ)")
        
        print(f"\n{'='*80}")
        print(f"ğŸ‰ ë°°ì¹˜ ì²˜ë¦¬ ì™„ë£Œ!")
        print(f"{'='*80}\n")


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(description='EBS ì˜ì–´ ê°•ì˜ ëŒ€í™” êµ¬ê°„ ìë™ ì¶”ì¶œ')
    parser.add_argument('--file', '-f', type=str, help='ì²˜ë¦¬í•  íŠ¹ì • MP3 íŒŒì¼ ê²½ë¡œ')
    parser.add_argument('--folder', type=str, default='.', help='ì²˜ë¦¬í•  í´ë” (ê¸°ë³¸: í˜„ì¬ í´ë”)')
    parser.add_argument('--model', type=str, default='tiny', choices=['tiny', 'base', 'small', 'medium', 'large'],
                       help='Whisper ëª¨ë¸ í¬ê¸° (ê¸°ë³¸: tiny)')
    
    args = parser.parse_args()
    
    if not HAS_INA:
        print("="*80)
        print("âš ï¸  inaSpeechSegmenterê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
        print("="*80)
        print("\në‹¤ìŒ ëª…ë ¹ìœ¼ë¡œ ì„¤ì¹˜í•˜ì„¸ìš”:")
        print("  pip install inaSpeechSegmenter tensorflow\n")
        print("ì„¤ì¹˜ ì—†ì´ ê³„ì†í•˜ë ¤ë©´ fast_extract.pyë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.")
        print("="*80)
        return
    
    extractor = SmartConversationExtractor(model_size=args.model)
    
    # ë‹¨ì¼ íŒŒì¼ ì²˜ë¦¬
    if args.file:
        if not os.path.exists(args.file):
            print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {args.file}")
            return
        
        extractor.load_models()
        success, anchor_time, output_path = extractor.find_anchor_and_extract_smart(args.file)
        
        if success:
            print(f"\nâœ… ì²˜ë¦¬ ì™„ë£Œ!")
            print(f"   ì¶œë ¥ íŒŒì¼: {output_path}")
        else:
            print("\nâŒ ì²˜ë¦¬ ì‹¤íŒ¨")
    
    # í´ë” ì „ì²´ ì²˜ë¦¬
    else:
        extractor.process_folder(
            folder_path=args.folder,
            pattern='*.mp3',
            exclude_patterns=['extracted_', 'transcription_', 'ì™•ì´ˆë³´ì˜ì–´_', 'script_']
        )


if __name__ == "__main__":
    main()
