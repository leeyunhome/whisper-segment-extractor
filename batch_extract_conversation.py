"""
EBS ì˜ì–´ ê°•ì˜ MP3 ë°°ì¹˜ ì²˜ë¦¬ ìŠ¤í¬ë¦½íŠ¸ (ìŒì•… ê¸°ë°˜ ì„¸ê·¸ë©˜í…Œì´ì…˜)

í´ë” ë‚´ ëª¨ë“  MP3 íŒŒì¼ì—ì„œ "ì „ì²´ëŒ€í™”" ì•µì»¤ë¥¼ ì°¾ì•„ 
ìŒì•…ìœ¼ë¡œ ë‘˜ëŸ¬ì‹¸ì¸ ì˜ì–´ ëŒ€í™” êµ¬ê°„ì„ ìë™ìœ¼ë¡œ ì¶”ì¶œí•©ë‹ˆë‹¤.

Requirements:
    pip install openai-whisper pydub inaSpeechSegmenter tensorflow
    
    # FFmpeg ì„¤ì¹˜ í•„ìš”
    # Windows: choco install ffmpeg
"""

import whisper
import os
import glob
from pydub import AudioSegment
import json
from pathlib import Path

try:
    from inaSpeechSegmenter import Segmenter
    HAS_INA = True
except ImportError:
    HAS_INA = False
    print("âš ï¸  inaSpeechSegmenterê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
    print("   pip install inaSpeechSegmenter ë¡œ ì„¤ì¹˜í•˜ì„¸ìš”")


class BatchConversationExtractor:
    def __init__(self, model_size='base', start_time_hint=1380):
        """
        Args:
            model_size: Whisper ëª¨ë¸ í¬ê¸°
            start_time_hint: ì•µì»¤ ê²€ìƒ‰ ì‹œì‘ ì‹œê°„ (ì´ˆ), ê¸°ë³¸ 23ë¶„ = 1380ì´ˆ
        """
        self.model_size = model_size
        self.start_time_hint = start_time_hint
        self.model = None
        self.segmenter = None
        
    def load_models(self):
        """Whisper ë° inaSpeechSegmenter ëª¨ë¸ ë¡œë”©"""
        if self.model is None:
            print(f"ğŸ”„ Whisper ëª¨ë¸ ë¡œë”© ì¤‘... (ëª¨ë¸: {self.model_size})")
            self.model = whisper.load_model(self.model_size)
            print("âœ… Whisper ëª¨ë¸ ë¡œë”© ì™„ë£Œ")
        
        if HAS_INA and self.segmenter is None:
            print("ğŸ”„ inaSpeechSegmenter ëª¨ë¸ ë¡œë”© ì¤‘...")
            self.segmenter = Segmenter()
            print("âœ… inaSpeechSegmenter ëª¨ë¸ ë¡œë”© ì™„ë£Œ")
    
    def find_anchor_optimized(self, audio_path, anchor_phrases=["ì „ì²´ëŒ€í™” ì£¼ì„¸ìš”", "ì „ì²´ëŒ€í™”", "ì „ì²´ ëŒ€í™”"]):
        """
        23ë¶„ ì´í›„ë¶€í„° ì•µì»¤ ë¬¸êµ¬ ê²€ìƒ‰ (ìµœì í™”)
        
        Returns:
            ì•µì»¤ ì¢…ë£Œ ì‹œê°„ (ì´ˆ) ë˜ëŠ” None
        """
        print(f"\n{'='*60}")
        print(f"ğŸµ íŒŒì¼: {os.path.basename(audio_path)}")
        print(f"{'='*60}")
        
        print(f"ğŸ”„ ì˜¤ë””ì˜¤ ì „ì‚¬ ì¤‘... (ì‹œì‘ ì‹œì : {self.start_time_hint/60:.1f}ë¶„ë¶€í„°)")
        
        # Whisper ì „ì‚¬
        result = self.model.transcribe(
            audio_path,
            language='ko',
            word_timestamps=True,
            verbose=False
        )
        
        # 23ë¶„ ì´í›„ ì„¸ê·¸ë¨¼íŠ¸ë§Œ ê²€ìƒ‰
        anchor_end_time = None
        for segment in result['segments']:
            # start_time_hint ì´í›„ ì„¸ê·¸ë¨¼íŠ¸ë§Œ í™•ì¸
            if segment['start'] >= self.start_time_hint:
                text = segment['text'].strip()
                
                for anchor in anchor_phrases:
                    if anchor in text:
                        anchor_end_time = segment['end']
                        print(f"âœ… ì•µì»¤ ë°œê²¬: '{text}'")
                        print(f"ğŸ“ ì¢…ë£Œ ì‹œì : {anchor_end_time:.2f}ì´ˆ ({anchor_end_time/60:.2f}ë¶„)")
                        return anchor_end_time, result
        
        print(f"âš ï¸  {self.start_time_hint/60:.1f}ë¶„ ì´í›„ì—ì„œ ì•µì»¤ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤")
        return None, result
    
    def extract_music_segment(self, audio_path, anchor_end_time, output_path):
        """
        inaSpeechSegmenterë¡œ ìŒì•…ìœ¼ë¡œ ë‘˜ëŸ¬ì‹¸ì¸ êµ¬ê°„ ì¶”ì¶œ
        
        Args:
            audio_path: ì›ë³¸ MP3 íŒŒì¼
            anchor_end_time: ì•µì»¤ ì¢…ë£Œ ì‹œê°„
            output_path: ì¶œë ¥ íŒŒì¼ ê²½ë¡œ
        """
        if not HAS_INA or self.segmenter is None:
            print("âš ï¸  inaSpeechSegmenterë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            print("   ê³ ì • ì‹œê°„(3ë¶„) ì¶”ì¶œë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤")
            return self._extract_simple(audio_path, anchor_end_time, output_path, 180)
        
        print("ğŸ”„ ìŒì„±/ìŒì•… ì„¸ê·¸ë©˜í…Œì´ì…˜ ë¶„ì„ ì¤‘...")
        segments = self.segmenter(audio_path)
        
        # ì•µì»¤ ì´í›„ êµ¬ê°„ë§Œ í•„í„°ë§
        target_segments = []
        for label, start, end in segments:
            if start >= anchor_end_time:
                target_segments.append((label, start, end))
        
        if not target_segments:
            print("âš ï¸  ì„¸ê·¸ë¨¼íŠ¸ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ê³ ì • ì‹œê°„(3ë¶„) ì¶”ì¶œë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤")
            return self._extract_simple(audio_path, anchor_end_time, output_path, 180)
        
        print(f"\nğŸ“Š ì•µì»¤ ì´í›„ ì„¸ê·¸ë¨¼íŠ¸ ë¶„ì„:")
        for label, start, end in target_segments[:10]:  # ì²˜ìŒ 10ê°œë§Œ ì¶œë ¥
            print(f"  {label:12s} {start:7.2f}ì´ˆ ~ {end:7.2f}ì´ˆ (ê¸¸ì´: {end-start:.2f}ì´ˆ)")
        if len(target_segments) > 10:
            print(f"  ... ì™¸ {len(target_segments)-10}ê°œ ì„¸ê·¸ë¨¼íŠ¸")
        
        # ìŒì•…/ì˜ì–´ êµ¬ê°„ ì°¾ê¸°
        # ì „ëµ: musicìœ¼ë¡œ ì‹œì‘í•˜ê±°ë‚˜, male/female ìŒì„±ì´ í¬í•¨ëœ ì—°ì† êµ¬ê°„
        extract_start = anchor_end_time
        extract_end = anchor_end_time
        
        # ìŒì•…ì´ë‚˜ ì˜ì–´ ìŒì„±ì´ ì—°ì†ë˜ëŠ” êµ¬ê°„ ì°¾ê¸°
        looking_for_content = True
        silence_threshold = 2.0  # 2ì´ˆ ì´ìƒ ê³µë°±ì´ë©´ ì¢…ë£Œ
        
        for i, (label, start, end) in enumerate(target_segments):
            # music, male, femaleì€ ì½˜í…ì¸ ë¡œ ê°„ì£¼
            if label in ['music', 'male', 'female']:
                if looking_for_content:
                    extract_start = start
                    looking_for_content = False
                extract_end = end
            elif label == 'noEnergy':
                # ì¹¨ë¬µ êµ¬ê°„: ë„ˆë¬´ ê¸¸ë©´ ì¢…ë£Œ
                if not looking_for_content and (end - start) > silence_threshold:
                    print(f"  â¹ï¸  ê¸´ ì¹¨ë¬µ ê°ì§€ ({end-start:.2f}ì´ˆ), ì¶”ì¶œ ì¢…ë£Œ")
                    break
            else:
                # ê¸°íƒ€ (í•œêµ­ì–´ ë“±): ì¢…ë£Œ
                if not looking_for_content:
                    print(f"  â¹ï¸  ê¸°íƒ€ ìŒì„± ê°ì§€ (ë¼ë²¨: {label}), ì¶”ì¶œ ì¢…ë£Œ")
                    break
        
        duration = extract_end - extract_start
        print(f"\nâœ‚ï¸  ì¶”ì¶œ êµ¬ê°„: {extract_start:.2f}ì´ˆ ~ {extract_end:.2f}ì´ˆ (ê¸¸ì´: {duration:.2f}ì´ˆ = {duration/60:.2f}ë¶„)")
        
        # ì˜¤ë””ì˜¤ ì¶”ì¶œ
        print("ğŸ”„ ì˜¤ë””ì˜¤ ë¡œë”© ë° ì¶”ì¶œ ì¤‘...")
        audio = AudioSegment.from_mp3(audio_path)
        
        start_ms = int(extract_start * 1000)
        end_ms = int(extract_end * 1000)
        
        extracted = audio[start_ms:end_ms]
        
        # ì €ì¥
        print(f"ğŸ’¾ ì €ì¥ ì¤‘: {output_path}")
        extracted.export(
            output_path,
            format='mp3',
            bitrate='320k',
            parameters=["-q:a", "0"]
        )
        
        print(f"âœ… ì¶”ì¶œ ì™„ë£Œ: {len(extracted)/1000:.2f}ì´ˆ")
        return True
    
    def _extract_simple(self, audio_path, anchor_end_time, output_path, duration=180):
        """ê³ ì • ì‹œê°„ ì¶”ì¶œ (fallback)"""
        print(f"âœ‚ï¸  ê³ ì • êµ¬ê°„ ì¶”ì¶œ: {anchor_end_time:.2f}ì´ˆ ~ {anchor_end_time+duration:.2f}ì´ˆ")
        
        audio = AudioSegment.from_mp3(audio_path)
        start_ms = int(anchor_end_time * 1000)
        end_ms = min(start_ms + (duration * 1000), len(audio))
        
        extracted = audio[start_ms:end_ms]
        
        print(f"ğŸ’¾ ì €ì¥ ì¤‘: {output_path}")
        extracted.export(
            output_path,
            format='mp3',
            bitrate='320k',
            parameters=["-q:a", "0"]
        )
        
        print(f"âœ… ì¶”ì¶œ ì™„ë£Œ: {len(extracted)/1000:.2f}ì´ˆ")
        return True
    
    def process_file(self, audio_path, output_dir=None):
        """
        ë‹¨ì¼ íŒŒì¼ ì²˜ë¦¬
        
        Returns:
            (ì„±ê³µ ì—¬ë¶€, ì¶œë ¥ íŒŒì¼ ê²½ë¡œ)
        """
        try:
            # ì•µì»¤ ì°¾ê¸°
            anchor_time, transcription = self.find_anchor_optimized(audio_path)
            
            if anchor_time is None:
                print("âŒ ì•µì»¤ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ê±´ë„ˆëœë‹ˆë‹¤.\n")
                return False, None
            
            # ì¶œë ¥ ê²½ë¡œ ê²°ì •
            if output_dir is None:
                output_dir = os.path.dirname(audio_path)
            
            base_name = Path(audio_path).stem
            output_path = os.path.join(output_dir, f"extracted_conversation_{base_name}.mp3")
            
            # ìŒì•… êµ¬ê°„ ì¶”ì¶œ
            success = self.extract_music_segment(audio_path, anchor_time, output_path)
            
            # ì „ì‚¬ ê²°ê³¼ ì €ì¥ (ë””ë²„ê¹…ìš©)
            transcription_path = os.path.join(output_dir, f"transcription_{base_name}.json")
            with open(transcription_path, 'w', encoding='utf-8') as f:
                json.dump(transcription, f, ensure_ascii=False, indent=2)
            print(f"ğŸ’¾ ì „ì‚¬ ê²°ê³¼ ì €ì¥: {transcription_path}")
            
            return success, output_path
            
        except Exception as e:
            print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}\n")
            import traceback
            traceback.print_exc()
            return False, None
    
    def process_folder(self, folder_path='.', pattern='*.mp3', exclude_pattern='extracted_*'):
        """
        í´ë” ë‚´ ëª¨ë“  MP3 íŒŒì¼ ë°°ì¹˜ ì²˜ë¦¬
        
        Args:
            folder_path: ê²€ìƒ‰í•  í´ë”
            pattern: MP3 íŒŒì¼ íŒ¨í„´
            exclude_pattern: ì œì™¸í•  íŒŒì¼ íŒ¨í„´
        """
        # ëª¨ë¸ ë¡œë”©
        self.load_models()
        
        # MP3 íŒŒì¼ ê²€ìƒ‰
        search_path = os.path.join(folder_path, pattern)
        all_files = glob.glob(search_path)
        
        # ì œì™¸ íŒ¨í„´ í•„í„°ë§
        mp3_files = [f for f in all_files if not os.path.basename(f).startswith('extracted_')]
        
        if not mp3_files:
            print(f"âš ï¸  {folder_path}ì—ì„œ MP3 íŒŒì¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤")
            return
        
        print(f"\n{'='*60}")
        print(f"ğŸ“ í´ë”: {os.path.abspath(folder_path)}")
        print(f"ğŸµ ë°œê²¬ëœ íŒŒì¼: {len(mp3_files)}ê°œ")
        print(f"{'='*60}\n")
        
        for i, file_path in enumerate(mp3_files, 1):
            print(f"\n[{i}/{len(mp3_files)}] ì²˜ë¦¬ ì¤‘...")
            success, output_path = self.process_file(file_path)
            
            if success:
                print(f"âœ… ì„±ê³µ: {os.path.basename(output_path)}\n")
            else:
                print(f"âŒ ì‹¤íŒ¨: {os.path.basename(file_path)}\n")
        
        print(f"\n{'='*60}")
        print(f"ğŸ‰ ë°°ì¹˜ ì²˜ë¦¬ ì™„ë£Œ!")
        print(f"{'='*60}\n")


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    
    # ë°°ì¹˜ ì¶”ì¶œê¸° ì´ˆê¸°í™”
    extractor = BatchConversationExtractor(
        model_size='base',      # tiny, base, small, medium, large
        start_time_hint=1380    # 23ë¶„ = 1380ì´ˆë¶€í„° ê²€ìƒ‰ ì‹œì‘
    )
    
    # í˜„ì¬ í´ë”ì˜ ëª¨ë“  MP3 íŒŒì¼ ì²˜ë¦¬
    extractor.process_folder(
        folder_path='.',
        pattern='*.mp3',
        exclude_pattern='extracted_*'
    )


if __name__ == "__main__":
    main()
