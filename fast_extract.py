"""
EBS ì˜ì–´ ê°•ì˜ ëŒ€í™” êµ¬ê°„ ì¶”ì¶œ ìŠ¤í¬ë¦½íŠ¸ (ë¹ ë¥¸ ë²„ì „)

ë¶„ì„ ê²°ê³¼ ê¸°ë°˜:
- "ì „ì²´ëŒ€í™”" ì•µì»¤ ì´í›„ ì•½ 45-60ì´ˆ êµ¬ê°„ ì¶”ì¶œ
- 23ë¶„ ì´í›„ ê²€ìƒ‰ ì‹œì‘
- Whisper tiny ëª¨ë¸ ì‚¬ìš©ìœ¼ë¡œ ì†ë„ í–¥ìƒ

Requirements:
    pip install openai-whisper pydub
"""

import whisper
import os
import glob
from pydub import AudioSegment
import json
from pathlib import Path


class FastConversationExtractor:
    def __init__(self, model_size='tiny'):
        """
        Args:
            model_size: Whisper ëª¨ë¸ í¬ê¸° (tiny ê¶Œì¥ - ë¹ ë¥´ê³  ì•µì»¤ ê°ì§€ì— ì¶©ë¶„)
        """
        self.model_size = model_size
        self.model = None
        
    def load_model(self):
        """Whisper ëª¨ë¸ ë¡œë”©"""
        if self.model is None:
            print(f"ğŸ”„ Whisper ëª¨ë¸ ë¡œë”© ì¤‘... (ëª¨ë¸: {self.model_size})")
            self.model = whisper.load_model(self.model_size)
            print("âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ\n")
    
    def find_anchor_and_extract(self, audio_path, 
                                search_start_time=1380,  # 23ë¶„
                                extraction_duration=50,   # 50ì´ˆ ì¶”ì¶œ (ë¶„ì„ ê²°ê³¼ í‰ê· )
                                start_offset=46,          # ì•µì»¤ ì´í›„ ìŒì•… ì‹œì‘ê¹Œì§€ ëŒ€ê¸° (ì´ˆ)
                                anchor_phrases=["ì „ì²´ëŒ€í™” ì£¼ì„¸ìš”", "ì „ì²´ëŒ€í™”", "ì „ì²´ ëŒ€í™”", "ì „ì²´ë˜ì–´", "ì „ì²´ ë˜ì–´"]):
        """
        ì•µì»¤ë¥¼ ì°¾ì•„ ëŒ€í™” êµ¬ê°„ ì¶”ì¶œ
        
        Args:
            audio_path: MP3 íŒŒì¼ ê²½ë¡œ
            search_start_time: ê²€ìƒ‰ ì‹œì‘ ì‹œê°„ (ì´ˆ)
            extraction_duration: ì¶”ì¶œ ê¸¸ì´ (ì´ˆ)
            start_offset: ì•µì»¤ ì¢…ë£Œ í›„ ì‹¤ì œ ì¶”ì¶œê¹Œì§€ ëŒ€ê¸° ì‹œê°„ (ì´ˆ) - ìŒì•… ì‹œì‘ê¹Œì§€ ëŒ€ê¸°
            anchor_phrases: ê²€ìƒ‰í•  ì•µì»¤ ë¬¸êµ¬ë“¤
            
        Returns:
            (ì„±ê³µ ì—¬ë¶€, ì•µì»¤ ì‹œê°„, ì¶”ì¶œ íŒŒì¼ ê²½ë¡œ)
        """
        print(f"{'='*80}")
        print(f"ğŸµ íŒŒì¼: {os.path.basename(audio_path)}")
        print(f"{'='*80}\n")
        
        # 1. ì „ì‚¬
        print(f"ğŸ”„ ì „ì‚¬ ì¤‘ (ê²€ìƒ‰ ì‹œì‘: {search_start_time/60:.1f}ë¶„ë¶€í„°)...")
        result = self.model.transcribe(
            audio_path,
            language='ko',
            word_timestamps=False,
            verbose=False
        )
        
        # ì „ì‚¬ ê²°ê³¼ ì €ì¥ (ë””ë²„ê¹…ìš©)
        base_name = Path(audio_path).stem
        transcription_path = f"transcription_{base_name}.json"
        with open(transcription_path, 'w', encoding='utf-8') as f:
            json.dump(result, f, ensure_ascii=False, indent=2)
        print(f"ğŸ’¾ ì „ì‚¬ ê²°ê³¼ ì €ì¥: {transcription_path}\n")
        
        # 2. ì•µì»¤ ê²€ìƒ‰
        print(f"ğŸ” ì•µì»¤ ë¬¸êµ¬ ê²€ìƒ‰ ì¤‘...")
        anchor_end_time = None
        segments = result['segments']
        
        # ë¨¼ì € ë‹¨ì¼ ì„¸ê·¸ë¨¼íŠ¸ì—ì„œ ê²€ìƒ‰
        for segment in segments:
            if segment['start'] >= search_start_time:
                text = segment['text'].strip()
                
                for anchor in anchor_phrases:
                    if anchor in text:
                        anchor_end_time = segment['end']
                        print(f"âœ… ì•µì»¤ ë°œê²¬!")
                        print(f"   í…ìŠ¤íŠ¸: '{text}'")
                        print(f"   ì‹œê°„: {anchor_end_time:.2f}ì´ˆ ({anchor_end_time/60:.2f}ë¶„)\n")
                        break
                
                if anchor_end_time:
                    break
        
        # ë‹¨ì¼ ì„¸ê·¸ë¨¼íŠ¸ì—ì„œ ëª» ì°¾ìœ¼ë©´ ì—°ì† ì„¸ê·¸ë¨¼íŠ¸ ë³‘í•© ê²€ìƒ‰
        if anchor_end_time is None:
            print(f"ğŸ” ì—°ì† ì„¸ê·¸ë¨¼íŠ¸ ë³‘í•© ê²€ìƒ‰ ì¤‘...")
            for i, segment in enumerate(segments):
                if segment['start'] >= search_start_time and i < len(segments) - 2:
                    # í˜„ì¬ + ë‹¤ìŒ 2ê°œ ì„¸ê·¸ë¨¼íŠ¸ ë³‘í•©
                    combined_text = (
                        segment['text'] + 
                        segments[i+1]['text'] + 
                        segments[i+2]['text']
                    ).strip()
                    
                    for anchor in anchor_phrases:
                        if anchor in combined_text:
                            anchor_end_time = segments[i+2]['end']
                            print(f"âœ… ì•µì»¤ ë°œê²¬ (ë³‘í•©)!")
                            print(f"   í…ìŠ¤íŠ¸: '{combined_text}'")
                            print(f"   ì‹œê°„: {anchor_end_time:.2f}ì´ˆ ({anchor_end_time/60:.2f}ë¶„)\n")
                            break
                    
                    if anchor_end_time:
                        break
        
        if anchor_end_time is None:
            print(f"âŒ ì•µì»¤ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤\n")
            return False, None, None
        
        # 3. ì˜¤ë””ì˜¤ ì¶”ì¶œ
        actual_start_time = anchor_end_time + start_offset
        print(f"âœ‚ï¸  êµ¬ê°„ ì¶”ì¶œ:")
        print(f"   ì•µì»¤ ì¢…ë£Œ: {anchor_end_time:.2f}ì´ˆ ({anchor_end_time/60:.2f}ë¶„)")
        print(f"   ìŒì•… ì‹œì‘ ëŒ€ê¸°: +{start_offset}ì´ˆ")
        print(f"   ì¶”ì¶œ ì‹œì‘: {actual_start_time:.2f}ì´ˆ ({actual_start_time/60:.2f}ë¶„)")
        print(f"   ì¶”ì¶œ ì¢…ë£Œ: {actual_start_time + extraction_duration:.2f}ì´ˆ")
        print(f"   ê¸¸ì´: {extraction_duration}ì´ˆ\n")
        
        audio = AudioSegment.from_mp3(audio_path)
        start_ms = int(actual_start_time * 1000)
        end_ms = min(start_ms + (extraction_duration * 1000), len(audio))
        
        extracted = audio[start_ms:end_ms]
        
        # 4. ì €ì¥
        output_path = f"extracted_{base_name}.mp3"
        print(f"ğŸ’¾ ì €ì¥ ì¤‘: {output_path}")
        extracted.export(
            output_path,
            format='mp3',
            bitrate='320k',
            parameters=["-q:a", "0"]
        )
        
        actual_duration = len(extracted) / 1000
        print(f"âœ… ì¶”ì¶œ ì™„ë£Œ: {actual_duration:.1f}ì´ˆ\n")
        
        return True, anchor_end_time, output_path
    
    def process_folder(self, folder_path='.', 
                      pattern='*.mp3', 
                      exclude_patterns=['extracted_', 'transcription_', 'ì™•ì´ˆë³´ì˜ì–´_'],
                      extraction_duration=50,
                      start_offset=46):
        """
        í´ë” ë‚´ MP3 íŒŒì¼ ë°°ì¹˜ ì²˜ë¦¬
        
        Args:
            folder_path: ê²€ìƒ‰í•  í´ë”
            pattern: íŒŒì¼ íŒ¨í„´
            exclude_patterns: ì œì™¸í•  íŒŒì¼ëª… íŒ¨í„´ë“¤
            extraction_duration: ì¶”ì¶œ ê¸¸ì´ (ì´ˆ)
            start_offset: ì•µì»¤ ì¢…ë£Œ í›„ ì¶”ì¶œ ì‹œì‘ê¹Œì§€ ëŒ€ê¸° ì‹œê°„ (ì´ˆ)
        """
        # ëª¨ë¸ ë¡œë”©
        self.load_model()
        
        # íŒŒì¼ ê²€ìƒ‰
        search_path = os.path.join(folder_path, pattern)
        all_files = glob.glob(search_path)
        
        # ì œì™¸ íŒ¨í„´ í•„í„°ë§
        mp3_files = []
        for f in all_files:
            basename = os.path.basename(f)
            should_exclude = False
            for exclude_pattern in exclude_patterns:
                if basename.startswith(exclude_pattern):
                    should_exclude = True
                    break
            if not should_exclude:
                mp3_files.append(f)
        
        if not mp3_files:
            print(f"âš ï¸  ì²˜ë¦¬í•  MP3 íŒŒì¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤")
            return
        
        print(f"\n{'='*80}")
        print(f"ğŸ“ í´ë”: {os.path.abspath(folder_path)}")
        print(f"ğŸµ ë°œê²¬ëœ íŒŒì¼: {len(mp3_files)}ê°œ")
        print(f"{'='*80}\n")
        
        results = []
        
        for i, file_path in enumerate(mp3_files, 1):
            print(f"[{i}/{len(mp3_files)}] ì²˜ë¦¬ ì¤‘...\n")
            
            success, anchor_time, output_path = self.find_anchor_and_extract(
                file_path,
                extraction_duration=extraction_duration,
                start_offset=start_offset
            )
            
            results.append({
                'file': os.path.basename(file_path),
                'success': success,
                'anchor_time': anchor_time,
                'output': os.path.basename(output_path) if output_path else None
            })
            
            print()
        
        # ê²°ê³¼ ìš”ì•½
        print(f"\n{'='*80}")
        print(f"ğŸ“Š ì²˜ë¦¬ ê²°ê³¼ ìš”ì•½")
        print(f"{'='*80}\n")
        
        success_count = sum(1 for r in results if r['success'])
        print(f"âœ… ì„±ê³µ: {success_count}/{len(results)}ê°œ\n")
        
        for r in results:
            status = "âœ…" if r['success'] else "âŒ"
            print(f"{status} {r['file']}")
            if r['success']:
                print(f"   â†’ {r['output']} (ì•µì»¤: {r['anchor_time']:.1f}ì´ˆ)")
        
        print(f"\n{'='*80}")
        print(f"ğŸ‰ ë°°ì¹˜ ì²˜ë¦¬ ì™„ë£Œ!")
        print(f"{'='*80}\n")


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    
    extractor = FastConversationExtractor(model_size='tiny')
    
    # í˜„ì¬ í´ë”ì˜ MP3 íŒŒì¼ ì²˜ë¦¬
    extractor.process_folder(
        folder_path='.',
        pattern='*.mp3',
        exclude_patterns=['extracted_', 'transcription_', 'ì™•ì´ˆë³´ì˜ì–´_'],
        extraction_duration=50,  # 50ì´ˆ ì¶”ì¶œ (ë¶„ì„ ê²°ê³¼: í‰ê·  50ì´ˆ, ë²”ìœ„ 46-57ì´ˆ)
        start_offset=46          # ì•µì»¤ ì´í›„ 46ì´ˆ ëŒ€ê¸° (ìŒì•… ì‹œì‘ê¹Œì§€)
    )


if __name__ == "__main__":
    main()
